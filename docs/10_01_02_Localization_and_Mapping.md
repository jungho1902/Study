# 파트 10: AI 기반 로봇 응용 (AI-Powered Robotic Applications)

## 10.1. 자율 이동 로봇 (Autonomous Mobile Robots, AMR) & 자율주행

### 10.1.2. 위치 추정 및 지도 작성 (Localization & Mapping)

**들어가며**

"나는 지금 어디에 있는가?" 그리고 "내 주변은 어떻게 생겼는가?"
이 두 가지 근본적인 질문에 답하는 기술이 바로 **위치 추정(Localization)**과 **지도 작성(Mapping)**입니다. 자율 이동 로봇이 성공적으로 임무를 수행하기 위해서는 자신의 위치를 정확히 알고, 주변 환경에 대한 지도를 가지고 있어야 합니다. 하지만 미리 만들어진 완벽한 지도가 없는 환경에서 로봇은 이 두 가지를 동시에 수행해야 하는 '닭과 달걀' 문제에 직면하게 됩니다. 이 문제를 해결하는 기술이 바로 **SLAM (Simultaneous Localization and Mapping, 동시적 위치 추정 및 지도 작성)**입니다.

이 장에서는 SLAM의 핵심 개념과 이를 구현하는 대표적인 알고리즘들에 대해 알아보겠습니다.

---

**1. SLAM (Simultaneous Localization and Mapping) 이란?**

SLAM은 말 그대로, 로봇이 임의의 공간을 이동하면서 **자신의 위치를 추정함과 동시에 주변 환경의 지도를 작성하는 기술**입니다. 로봇은 센서(LiDAR, 카메라 등) 데이터를 이용해 주변 환경의 특징점(Landmark)을 인식하고, 이 특징점들을 기준으로 지도를 만들어나갑니다. 동시에, 생성된 지도와 센서 데이터를 비교하여 지도 상에서 자신의 상대적인 위치를 추정합니다. 이 과정이 반복되면서 지도와 위치 추정의 정확도가 점차 향상됩니다.

- **SLAM의 핵심 과제:**
  - **데이터 연관 (Data Association):** "지금 보고 있는 이 특징점이 과거에 봤던 그 특징점과 같은 것인가?"를 알아내는 문제입니다. 잘못된 연관은 지도에 큰 오류를 유발합니다.
  - **정확성 및 일관성:** 생성된 지도와 추정된 위치가 실제와 얼마나 일치하는가. 시간이 지나도 누적 오차가 최소화되어야 합니다.
  - **강건성(Robustness):** 센서 노이즈, 급격한 움직임, 환경 변화 등에도 안정적으로 동작하는가.
  - **실시간성:** 로봇의 움직임에 맞춰 빠르게 계산을 수행할 수 있는가.

---

**2. 주요 SLAM 알고리즘**

SLAM 문제는 본질적으로 불확실성을 다루는 확률적 추정 문제입니다. 시간이 지남에 따라 로봇의 움직임과 센서 측정에 오차가 누적되기 때문입니다. 이를 해결하기 위해 다양한 확률 필터 및 최적화 기법이 사용됩니다.

#### 2.1. 필터 기반 SLAM (Filter-based SLAM)

- **EKF SLAM (Extended Kalman Filter SLAM):**
  - **개념:** 확장 칼만 필터(EKF)를 사용하여 로봇의 위치와 랜드마크의 위치를 동시에 추정합니다. 시스템의 상태 벡터에 로봇의 자세(pose)와 모든 랜드마크의 좌표를 포함하여 관리합니다.
  - **장점:** 알고리즘이 비교적 간단하고 계산량이 적어 초창기 SLAM 연구를 주도했습니다.
  - **단점:**
    - 랜드마크의 수가 늘어날수록 상태 벡터의 크기가 기하급수적으로 커져($`O(N^2)`$) 계산량이 폭증합니다.
    - 강한 비선형 환경에서는 선형화 오차로 인해 발산할 위험이 있습니다.

- **파티클 필터 SLAM (Particle Filter SLAM / Rao-Blackwellized Particle Filter):**
  - **개념:** 수많은 **파티클(particle)**을 사용하여 로봇의 가능한 위치에 대한 확률 분포를 표현합니다. 각 파티클은 로봇의 특정 경로(trajectory) 가설과 그에 해당하는 지도를 가집니다.
  - **동작:**
    1. **샘플링:** 로봇의 움직임에 따라 파티클을 이동시킵니다.
    2. **중요도 계산:** 센서 측정값을 바탕으로, 각 파티클이 얼마나 실제 상황과 부합하는지(likelihood) 계산하여 가중치(weight)를 부여합니다.
    3. **리샘플링:** 가중치가 높은 파티클은 복제하고, 낮은 파티클은 제거하여 중요한 가설에 집중합니다.
  - **장점:** 비선형, 비-가우시안 환경에서도 강건하게 동작합니다. EKF SLAM의 데이터 연관(data association) 문제를 완화합니다.
  - **단점:** 파티클의 수가 많아지면 계산량이 많아지고, 파티클 고갈(particle depletion) 문제가 발생할 수 있습니다.

#### 2.2. 최적화 기반 SLAM (Optimization-based SLAM)

- **GraphSLAM (그래프 기반 SLAM):**
  - **개념:** SLAM 문제를 **그래프 최적화(Graph Optimization)** 문제로 재정의합니다. 로봇의 경로(자세)와 랜드마크를 그래프의 **노드(Node)**로, 로봇의 움직임과 센서 측정값을 **엣지(Edge)**로 표현합니다.
  - **동작:**
    1. **그래프 구성:** 로봇이 이동하며 측정한 모든 데이터를 노드와 엣지로 연결하여 전체 그래프를 구성합니다.
    2. **오차 최소화:** 엣지는 노드 간의 제약 조건(constraint)을 나타내며, 이 제약 조건을 가장 잘 만족시키는 노드들의 위치를 찾는 방식으로 전체적인 오차(누적 오차)를 최소화합니다. 이를 '비선형 최소제곱법(Non-linear Least Squares)'으로 풉니다.
  - **장점:** 전체 경로를 한번에 최적화하므로 일관성 있는 지도를 만들 수 있습니다. (Full SLAM) EKF와 달리 과거의 추정치를 수정할 수 있어 정확도가 높습니다. 특히, 이전에 방문했던 장소를 다시 인식하여(Loop Closing) 누적된 오차를 전체적으로 보정하는 데 매우 효과적입니다.
  - **단점:** 주기적으로 대규모 최적화를 수행해야 하므로 계산량이 많을 수 있습니다. (최근에는 실시간 수행을 위한 기법들이 많이 연구되었습니다.)

---

**3. 주요 SLAM 기술**

어떤 센서를 주로 사용하느냐에 따라 SLAM 기술은 크게 나뉩니다.

- **Visual SLAM (비전 슬램):**
  - **센서:** 단안(Monocular), 양안(Stereo), RGB-D 등 카메라를 주 센서로 사용합니다.
  - **접근 방식:**
    - **특징점 기반 (Feature-based):** 이미지에서 ORB, SIFT와 같은 구별되는 특징점을 추출하고, 이들의 위치를 추적하여 카메라의 움직임을 계산합니다. (예: **ORB-SLAM**)
    - **직접 방식 (Direct):** 특징점 추출 없이, 픽셀의 밝기 값 자체를 사용하여 이미지 간의 변화를 통해 카메라 움직임을 직접 추정합니다. 움직임이 빠르거나 특징점이 적은 환경에 강건합니다. (예: **DSO**)
  - **장점:** 저렴한 센서로 풍부한 환경 정보를 얻을 수 있으며, 랜드마크 재인식을 통한 루프 클로징에 강합니다.
  - **단점:** 실제 크기(scale)를 알기 어렵고(특히 단안 카메라), 조명 변화나 빠른 움직임에 취약할 수 있습니다.

- **LiDAR SLAM (라이다 슬램):**
  - **센서:** 2D 또는 3D LiDAR를 주 센서로 사용합니다.
  - **특징:** 연속적인 포인트 클라우드 데이터를 직접 정합(scan matching)하여 로봇의 움직임을 추정하고 지도를 작성합니다. 정밀한 거리 측정 덕분에 매우 정확한 지도를 만들 수 있습니다.
  - **주요 기술 (ROS에서 널리 사용):**
    - **GMapping:** 파티클 필터 기반의 2D LiDAR SLAM. 계산 효율이 좋아 저사양 시스템에서도 널리 사용됩니다.
    - **Cartographer:** 구글에서 개발한 그래프 기반의 2D/3D LiDAR SLAM. 루프 클로징 성능이 매우 뛰어납니다.

**결론**

SLAM은 자율 이동 로봇 기술의 핵심으로, 불확실한 환경 속에서 로봇에게 '공간 지능'을 부여합니다. 초기 필터 기반 방식에서부터 현재 주류를 이루는 최적화 기반 방식에 이르기까지, SLAM 기술은 센서 기술의 발전과 함께 계속해서 진화하고 있습니다. 최근에는 딥러닝을 결합하여 지도에 의미 정보(예: '이곳은 문', '저것은 의자')를 부여하는 **Semantic SLAM**으로 발전하며, 로봇이 환경을 더 깊이 이해하고 상호작용하는 시대로 나아가고 있습니다.
