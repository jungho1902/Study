# 비용 함수 (Cost Function) / 손실 함수 (Loss Function)

머신러닝 모델을 학습시키는 과정은 '모델이 얼마나 좋은가'를 측정하고, 그 측정치를 바탕으로 모델을 개선해나가는 과정입니다. 여기서 **'모델이 얼마나 나쁜가'**를 정량적으로 측정하는 함수가 바로 비용 함수 또는 손실 함수입니다. 우리의 목표는 이 함수의 값을 최소화(minimize)하는 모델 파라미터를 찾는 것입니다.

이 용어들은 종종 혼용되기도 하지만, 미묘한 차이가 있습니다.

---

### 1. 손실 함수 (Loss Function)

**손실 함수(Loss Function)** 또는 오차 함수(Error Function)는 **단일 데이터 포인트(single data point)**에 대한 모델의 예측값과 실제값의 차이를 측정합니다.

- **역할:** 개별 데이터 샘플 하나에 대해 모델이 얼마나 잘못 예측했는지를 나타냅니다.
- **예시:**
  - **제곱 오차 (Squared Error):** `L = (ŷ - y)²`
    - 회귀 문제에서 하나의 데이터 포인트에 대한 예측값(`ŷ`)과 실제값(`y`)의 차이를 제곱합니다.
  - **크로스 엔트로피 오차 (Cross-Entropy Error):**
    - 분류 문제에서 하나의 데이터 포인트에 대한 모델의 예측 확률 분포와 실제 레이블 분포의 차이를 측정합니다.

### 2. 비용 함수 (Cost Function)

**비용 함수(Cost Function)**는 **전체 훈련 데이터셋(entire training dataset)**에 대한 손실의 총합 또는 평균을 나타냅니다.

- **역할:** 전체 데이터셋에 대한 모델의 전반적인 성능을 하나의 숫자로 요약합니다. 경사 하강법과 같은 최적화 알고리즘은 바로 이 비용 함수의 값을 최소화하는 방향으로 모델 파라미터를 업데이트합니다.
- **계산:** 일반적으로 모든 데이터 포인트의 손실을 계산한 후, 이를 합산하거나 평균을 냅니다.
- **예시:**
  - **평균 제곱 오차 (Mean Squared Error, MSE):**
    - `Cost = (1/N) * Σ(ŷᵢ - yᵢ)²`
    - 각 데이터 포인트의 제곱 오차(손실)를 모두 더해 데이터 개수 `N`으로 나눈 평균값입니다.
  - **평균 크로스 엔트로피 오차 (Mean Cross-Entropy Error):**
    - `Cost = -(1/N) * Σ [yᵢlog(ŷᵢ) + (1-yᵢ)log(1-ŷᵢ)]` (이진 분류의 경우)
    - 각 데이터 포인트의 크로스 엔트로피 손실의 평균값입니다.

### 3. 목적 함수 (Objective Function)

**목적 함수(Objective Function)**는 최적화 과정에서 최대화하거나 최소화하려는 모든 종류의 함수를 가리키는 가장 상위의, 일반적인 용어입니다.

- 머신러닝에서는 대부분 비용 함수를 **최소화(Minimization)**하는 것이 목적이므로, 비용 함수는 목적 함수의 한 종류라고 할 수 있습니다.
- 경우에 따라서는, 가능도(Likelihood)를 **최대화(Maximization)**하는 것이 목적이 될 수도 있습니다. 이 경우 가능도 함수가 목적 함수가 됩니다. (이는 로그 가능도에 음수를 취해 최소화 문제로 바꿔 풀 수 있습니다.)

---

## 관계 요약

- **손실 함수:** 단일 데이터 포인트에 대한 오차.
- **비용 함수:** 전체 데이터셋에 대한 오차 (손실 함수의 총합 또는 평균).
- **목적 함수:** 학습을 통해 최소화 또는 최대화하려는 대상이 되는 함수 (주로 비용 함수).

**훈련 과정:**
1. 각 데이터 포인트에 대해 **손실**을 계산합니다.
2. 모든 데이터 포인트의 손실을 모아 **비용**을 계산합니다.
3. 이 **비용**을 **목적 함수**로 삼아, 그래디언트 디센트 알고리즘을 통해 이 값을 최소화하는 방향으로 모델 파라미터를 조정합니다.
4. 이 과정을 반복합니다.
