# 그래프 데이터의 이해

## 1. 그래프 데이터란?

**그래프(Graph)**는 **노드(Node)** 또는 **정점(Vertex)**이라고 불리는 개체(entity)들과, 이들 사이의 관계를 나타내는 **엣지(Edge)** 또는 **링크(Link)**로 구성된 데이터 구조입니다.

**수학적 정의:**
그래프는 $G = (V, E)$로 정의되며, 여기서:
- $V = \{v_1, v_2, ..., v_n\}$: 노드(정점)의 집합
- $E \subseteq V \times V$: 엣지(간선)의 집합

유클리드 공간에 존재하는 이미지(픽셀 그리드)나 텍스트(단어 시퀀스)와 달리, 그래프 데이터는 **비유클리드(Non-Euclidean)** 공간에서 관계와 상호작용을 표현하는 데 특화되어 있으며, 우리 주변의 많은 복잡한 시스템을 모델링하는 데 사용됩니다.

**그래프 데이터의 특징:**
- **불규칙성(Irregularity):** 각 노드의 차수(degree)가 다름
- **순열 불변성(Permutation Invariance):** 노드 순서에 관계없이 동일한 그래프
- **희소성(Sparsity):** 대부분의 실제 그래프는 완전 그래프가 아님
- **동적 특성(Dynamic Nature):** 시간에 따라 구조가 변화할 수 있음

## 2. 그래프의 핵심 구성요소

### 2.1. 노드 (Nodes/Vertices)
그래프를 구성하는 기본 단위로, 개별적인 객체나 개체를 나타냅니다.

**노드 특징 표현:**
- 각 노드 $v_i$는 특징 벡터 $\mathbf{x}_i \in \mathbb{R}^d$를 가집니다
- 노드 특징 행렬: $\mathbf{X} \in \mathbb{R}^{n \times d}$ (n개 노드, d차원 특징)

**노드 차수(Degree):**
- 무방향 그래프: $deg(v_i) = \sum_{j=1}^n A_{ij}$
- 방향 그래프: 입차수 $deg_{in}(v_i) = \sum_{j=1}^n A_{ji}$, 출차수 $deg_{out}(v_i) = \sum_{j=1}^n A_{ij}$

### 2.2. 엣지 (Edges)
두 노드 사이의 관계 또는 연결을 나타냅니다.

**엣지 유형:**

**방향성에 따른 분류:**
- **무방향 그래프(Undirected Graph):** $A_{ij} = A_{ji}$ (대칭 행렬)
  - 예: 페이스북 친구 관계, 분자 내 원자 간 결합
- **방향 그래프(Directed Graph):** $A_{ij} \neq A_{ji}$ (비대칭 행렬)
  - 예: 트위터 팔로우 관계, 웹페이지 링크 구조

**가중치에 따른 분류:**
- **가중 그래프(Weighted Graph):** $A_{ij} \in \mathbb{R}$
  - 예: 교통 네트워크의 거리, 소셜 네트워크의 상호작용 빈도
- **비가중 그래프(Unweighted Graph):** $A_{ij} \in \{0, 1\}$

**엣지 특징:**
- 각 엣지 $(v_i, v_j)$는 특징 벡터 $\mathbf{e}_{ij} \in \mathbb{R}^{d_e}$를 가질 수 있음

### 2.3. 그래프 표현 방법

#### 인접 행렬 (Adjacency Matrix)
그래프의 연결 구조를 나타내는 핵심 행렬입니다.

**정의:**
$$A_{ij} = \begin{cases} 
w_{ij} & \text{if } (v_i, v_j) \in E \\
0 & \text{otherwise}
\end{cases}$$

**특성:**
- 크기: $n \times n$ (n = 노드 수)
- 메모리 복잡도: $O(n^2)$
- 희소 그래프에서는 메모리 비효율적

#### 인접 리스트 (Adjacency List)
각 노드에 대해 연결된 이웃 노드들의 리스트를 저장합니다.

**장점:**
- 메모리 효율적: $O(|E|)$
- 이웃 노드 순회가 빠름

#### 라플라시안 행렬 (Laplacian Matrix)
그래프의 구조적 특성을 분석하는 데 중요한 행렬입니다.

**정의:**
- 차수 행렬: $D_{ii} = deg(v_i)$, $D_{ij} = 0$ (i ≠ j)
- 라플라시안: $L = D - A$
- 정규화된 라플라시안: $L_{norm} = D^{-1/2}LD^{-1/2}$

**응용:**
- 그래프 클러스터링
- 스펙트럴 그래프 이론
- 그래프 신경망의 컨볼루션 연산

## 3. 그래프 데이터의 실제 예시

### 3.1. 소셜 네트워크 (Social Networks)
**구조:**
- **노드:** 사용자 (사람)
- **엣지:** 친구 관계, 팔로우, 메시지 교환 등

**특징:**
- 노드 특징: 나이, 성별, 관심사, 위치 정보
- 엣지 특징: 상호작용 빈도, 관계 강도, 메시지 유형
- 그래프 특성: Small-world property, Power-law degree distribution

**실제 데이터셋:**
- Facebook Social Circles: 4,039 노드, 88,234 엣지
- Twitter Social Network: 수백만 노드
- Reddit HyperLink Network: 55,863 노드

### 3.2. 추천 시스템 (Recommender Systems)
**구조:**
- **노드:** 사용자, 아이템 (영화, 상품 등)
- **엣지:** 구매/평가/클릭 기록 (상호작용)

**이분 그래프 모델:**
- User-Item 그래프: $G = (U \cup I, E)$
- User 노드: $U = \{u_1, u_2, ..., u_m\}$
- Item 노드: $I = \{i_1, i_2, ..., i_n\}$

**실제 응용:**
- Netflix 영화 추천: 48만 사용자, 1만 8천 영화
- Amazon 상품 추천: 수십억 상호작용
- Spotify 음악 추천: 콘텐츠 기반 + 협업 필터링

### 3.3. 분자 구조 (Molecular Structures)
**구조:**
- **노드:** 원자 (C, N, O, H 등)
- **엣지:** 화학적 결합 (단일/이중/삼중 결합)

**분자 그래프 특징:**
- 노드 특징: 원자 번호, 전하, 혼성화 상태
- 엣지 특징: 결합 유형, 결합 차수, 방향성
- 그래프 특성: 평면성, 고리 구조, 작용기

**응용 분야:**
- 신약 발견 (Drug Discovery)
- 분자 특성 예측 (QSAR)
- 화학 반응 예측

**실제 데이터셋:**
- QM9: 134,000개 분자
- ZINC: 수백만 개 화합물
- ChEMBL: 200만 개 생체활성 화합물

### 3.4. 지식 그래프 (Knowledge Graphs)
**구조:**
- **노드:** 개체 (Entity)
- **엣지:** 관계 (Relation)

**삼중체 형태:** (주어, 술어, 목적어)
- 예: (Einstein, born_in, Germany)
- 예: (Python, is_a, Programming_Language)

**실제 예시:**
- Google Knowledge Graph: 5억 개체, 35억 관계
- Wikidata: 1억 개체
- Facebook Social Graph: 30억 사용자

### 3.5. 생물학적 네트워크
**단백질 상호작용 네트워크 (PPI):**
- 노드: 단백질
- 엣지: 물리적/기능적 상호작용

**유전자 조절 네트워크:**
- 노드: 유전자/전사인자
- 엣지: 조절 관계 (활성화/억제)

**실제 응용:**
- 질병 유전자 발견
- 약물 표적 식별
- 진화 연구

### 3.6. 교통 및 물류 네트워크
**도로 네트워크:**
- 노드: 교차로, 도시
- 엣지: 도로, 거리/시간 가중치

**항공 네트워크:**
- 노드: 공항
- 엣지: 항공편, 승객 수/운항 빈도

**최적화 문제:**
- 최단 경로 찾기
- 교통량 예측
- 물류 경로 최적화

### 3.7. 신경망 구조 (Neural Network Architecture)
**구조:**
- 노드: 뉴런/레이어
- 엣지: 연결/정보 흐름

**응용:**
- Neural Architecture Search (NAS)
- 모델 압축 및 가지치기
- 연합 학습 토폴로지

## 4. 기존 딥러닝 모델의 한계

### 4.1. 구조적 가정의 한계
기존 딥러닝 모델들은 특정한 데이터 구조를 가정합니다:

**CNN (Convolutional Neural Networks):**
- **가정:** 규칙적인 그리드(grid) 구조 (예: 이미지의 픽셀 배열)
- **특징:** 지역적 수용 영역(local receptive field), 공유 가중치
- **수식:** $f(x) = \sigma(W * x + b)$ (컨볼루션 연산)

**RNN (Recurrent Neural Networks):**
- **가정:** 순차적인(sequential) 구조 (예: 텍스트의 단어 순서)
- **특징:** 시간적 의존성, 메모리 메커니즘
- **수식:** $h_t = \tanh(W_{hh}h_{t-1} + W_{xh}x_t + b)$

### 4.2. 그래프 데이터에 적용 시 문제점

**1. 불규칙성 (Irregularity)**
- 각 노드의 이웃 수가 다름: $|N(v_i)| \neq |N(v_j)|$
- 고정된 크기의 필터나 커널 적용 불가능

**2. 순열 불변성 (Permutation Invariance)**
- 노드 순서가 바뀌어도 동일한 그래프
- 기존 모델은 입력 순서에 민감함

**3. 희소성 (Sparsity)**
- 대부분의 실제 그래프는 희소함: $|E| \ll |V|^2$
- 인접 행렬의 대부분이 0, 계산 비효율성

**4. 동적 크기 (Variable Size)**
- 그래프마다 노드/엣지 수가 다름
- 배치 처리의 어려움

### 4.3. 전통적 접근법의 한계

**피처 엔지니어링 방법:**
- 핸드크래프트 특징 추출 (degree, clustering coefficient 등)
- 그래프의 복잡한 구조 정보 손실
- 도메인 전문 지식 필요

**그래프 커널 방법:**
- 부분 그래프 패턴 비교
- 계산 복잡도가 높음: $O(n^6)$
- 확장성 문제

**행렬 분해 방법:**
- DeepWalk, Node2Vec 등
- 그래프 구조를 벡터 공간으로 임베딩
- 표현 학습 능력 제한

### 4.4. GNN의 필요성

이러한 한계를 극복하기 위해 **그래프 신경망(Graph Neural Network, GNN)**이 등장했습니다:

**핵심 아이디어:**
1. **메시지 전파(Message Passing):** 이웃 노드 간 정보 교환
2. **집계 함수(Aggregation):** 이웃 정보를 통합
3. **순열 불변성:** 노드 순서에 무관한 연산
4. **다층 구조:** 계층적 표현 학습

**수학적 표현:**
$$h_v^{(l+1)} = \text{UPDATE}^{(l)}\left(h_v^{(l)}, \text{AGGREGATE}^{(l)}\left(\{h_u^{(l)} : u \in N(v)\}\right)\right)$$

여기서:
- $h_v^{(l)}$: l번째 레이어에서 노드 v의 표현
- $N(v)$: 노드 v의 이웃 집합
- UPDATE, AGGREGATE: 학습 가능한 함수

**장점:**
- 그래프 구조를 직접 활용
- 엔드투엔드 학습 가능
- 다양한 그래프 태스크에 적용 가능
- 확장성 우수

## 5. 그래프 데이터의 특수성과 도전과제

### 5.1. 구조적 특성

**작은 세상 효과 (Small World Property):**
- 평균 경로 길이가 짧음: $\bar{d} \propto \log n$
- 클러스터링 계수가 높음

**무척도 네트워크 (Scale-free Networks):**
- 차수 분포가 거듭제곱 법칙을 따름: $P(k) \sim k^{-\gamma}$
- 허브 노드의 존재

**커뮤니티 구조 (Community Structure):**
- 밀도가 높은 부분 그래프
- 모듈성(modularity) 최대화

### 5.2. 데이터 처리 도전과제

**확장성 문제:**
- 대규모 그래프 처리: 수백만~수십억 노드
- 메모리 및 계산 복잡도

**동적 그래프:**
- 시간에 따른 구조 변화
- 온라인/스트리밍 학습

**이질적 그래프 (Heterogeneous Graphs):**
- 다양한 노드/엣지 타입
- 멀티모달 정보 통합

**라벨 부족:**
- 지도 학습 데이터 수집 어려움
- 반지도/자기지도 학습 필요

그래프 신경망은 이러한 도전과제들을 해결하기 위한 강력한 도구로, 다음 섹션에서 GNN의 원리와 동작 방식을 자세히 살펴보겠습니다.
