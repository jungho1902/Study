# 지도학습 (Supervised Learning)

## 1. 지도학습이란?

**지도학습(Supervised Learning)**은 머신러닝의 가장 일반적이고 기본적인 유형 중 하나입니다. 이름에서 알 수 있듯이, **'정답'이 표시된 데이터를 가지고 '지도'를 받으며 학습**하는 방식입니다.

여기서 '정답'이란 **레이블(Label)** 또는 **타겟(Target)**을 의미합니다. 즉, 지도학습은 **입력(Input) 데이터와 그에 해당하는 정답(Label)이 쌍으로 이루어진 데이터셋**을 사용하여 모델을 훈련시킵니다.

- **핵심 목표:** 주어진 입력 데이터(X)를 보고, 그에 해당하는 정답(y)을 정확하게 예측하는 함수 `y = f(X)`를 학습하는 것입니다. 모델은 수많은 '문제와 정답' 쌍을 통해 입력과 출력 사이의 관계와 패턴을 학습합니다.

### 비유: 선생님과 함께 공부하는 학생
지도학습은 마치 학생이 선생님과 함께 공부하는 과정과 같습니다.
- **학생:** 머신러닝 모델
- **문제집:** 훈련 데이터 (Training Data)
- **정답지:** 레이블 (Labels)
- **선생님:** 정답지를 보고 학생의 답이 맞았는지 틀렸는지 채점해주는 역할

학생은 문제와 정답을 반복적으로 학습하면서, 처음 보는 문제가 나와도 정답을 맞출 수 있는 능력을 기르게 됩니다.

## 2. 지도학습의 주요 과제

지도학습은 예측하려는 '정답(레이블)'의 형태에 따라 크게 두 가지 주요 과제로 나뉩니다.

### 2.1. 분류 (Classification)
**분류**는 주어진 입력 데이터가 어떤 **정해진 카테고리(범주) 중 하나에 속하는지**를 예측하는 과제입니다. 예측해야 할 값이 이산적(discrete)이고, 순서가 없는 값입니다.

- **예시:**
  - **이진 분류 (Binary Classification):** '스팸'/'정상', '합격'/'불합격'처럼 두 개의 클래스 중 하나로 분류합니다.
  - **다중 분류 (Multi-class Classification):** '개'/'고양이'/'새', '정치'/'경제'/'사회'처럼 세 개 이상의 클래스 중 하나로 분류합니다.
- **주요 알고리즘:**
  - **로지스틱 회귀 (Logistic Regression):** 통계 기반의 알고리즘으로, 결과가 특정 클래스에 속할 확률을 계산하여 분류합니다.
  - **K-최근접 이웃 (k-NN):** 새로운 데이터와 가장 가까운 k개의 훈련 데이터의 클래스를 참고하여 분류하는 직관적인 방식입니다.
  - **서포트 벡터 머신 (SVM):** 클래스 간의 경계를 가장 명확하게 나누는 '결정 경계(Decision Boundary)'를 찾는 데 중점을 둔 알고리즘입니다.
  - **결정 트리 (Decision Tree):** 데이터를 '예/아니오' 질문을 반복하며 특정 그룹으로 나누는, 나무 형태의 모델입니다.
  - **랜덤 포레스트 (Random Forest):** 여러 개의 결정 트리를 만들어 그 결과를 종합(앙상블)하여 예측의 정확도를 높인 모델입니다.

### 2.2. 회귀 (Regression)
**회귀**는 주어진 입력 데이터를 바탕으로 **연속적인 숫자 값을 예측**하는 과제입니다. 예측해야 할 값이 연속적(continuous)이고, 순서가 있는 값입니다.

- **예시:**
  - 부동산 데이터를 바탕으로 '주택 가격' 예측하기
  - 광고 예산에 따른 '미래 매출액' 예측하기
  - 학생의 공부 시간을 바탕으로 '시험 점수' 예측하기
- **주요 알고리즘:**
  - **선형 회귀 (Linear Regression):** 데이터의 경향을 가장 잘 나타내는 하나의 직선을 찾는 가장 기본적인 회귀 알고리즘입니다.
  - **다항 회귀 (Polynomial Regression):** 직선이 아닌 곡선 형태의 관계를 모델링할 때 사용됩니다.
  - **릿지/라쏘 회귀 (Ridge/Lasso Regression):** 모델이 너무 복잡해지는 것을 방지하는 '규제(Regularization)'를 추가한 선형 회귀 모델입니다.
  - **서포트 벡터 회귀 (SVR):** SVM을 회귀 문제에 적용한 버전으로, 특정 오차 범위 내에서 최대한 많은 데이터가 포함되도록 모델을 학습합니다.

## 3. 일반화, 과대적합, 과소적합
지도학습의 궁극적인 목표는 훈련 데이터만 잘 맞추는 것이 아니라, **처음 보는 데이터(Unseen Data)에 대해서도 좋은 성능을 내는 것**입니다. 이를 **일반화(Generalization)**라고 합니다. 일반화 성능을 해치는 주요 문제는 다음과 같습니다.

- **과대적합 (Overfitting):** 모델이 훈련 데이터에만 너무 치중하여 학습한 나머지, 데이터의 세세한 노이즈까지 모두 외워버리는 현상입니다. 이 경우 훈련 데이터에 대한 성능은 매우 높지만, 실제 테스트 데이터에 대한 성능은 크게 떨어집니다. (예: 너무 열심히 공부해서 연습문제는 다 맞추지만, 응용 문제가 나오면 풀지 못하는 학생)
- **과소적합 (Underfitting):** 모델이 너무 단순하여 데이터에 내재된 패턴을 충분히 학습하지 못한 상태입니다. 훈련 데이터에 대한 성능과 테스트 데이터에 대한 성능 모두 낮게 나타납니다. (예: 시험 범위의 극히 일부만 공부하여 연습문제도, 실전 문제도 풀지 못하는 학생)

좋은 머신러닝 모델이란 과소적합과 과대적합 사이의 균형을 잘 맞춘, 일반화 성능이 뛰어난 모델을 의미합니다.

---

## 4. 핵심 요약 (Key Takeaways)
- **정의:** 지도학습은 '입력(X)-정답(y)'으로 구성된 **레이블된 데이터**로 모델을 학습시키는 방식입니다.
- **주요 과제:** 예측값이 범주형이면 **분류(Classification)**, 연속적인 수치이면 **회귀(Regression)** 문제를 풉니다.
- **궁극적 목표:** 단순히 훈련 데이터를 외우는 것이 아니라, 새로운 데이터에 대해서도 정확하게 예측하는 **일반화(Generalization)** 성능을 높이는 것입니다.
- **핵심 과제:** **과대적합(Overfitting)**과 **과소적합(Underfitting)**을 피하고 최적의 균형점을 찾는 것이 중요합니다.
- **한계:** 고품질의 레이블된 데이터를 구축하는 데 많은 **비용과 시간**이 필요하다는 점이 가장 큰 단점입니다.

이러한 레이블링 비용의 한계는 자연스럽게 '정답이 없는 데이터는 어떻게 활용할까?'라는 질문으로 이어지며, 이는 다음 주제인 **비지도학습(Unsupervised Learning)**의 중요한 동기가 됩니다.
