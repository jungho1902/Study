# 교차 검증 (Cross-Validation)

머신러닝 모델의 성능을 평가할 때, 전체 데이터를 **훈련 세트(Training Set)**와 **테스트 세트(Test Set)**로 한 번만 나누는 방식은 몇 가지 문제점을 가질 수 있습니다. 운 좋게 테스트 세트에 쉬운 데이터만 포함되거나, 혹은 운 나쁘게 어려운 데이터만 포함될 경우, 모델의 일반화 성능을 제대로 평가했다고 보기 어렵습니다.

**교차 검증(Cross-Validation)**은 이러한 문제를 해결하기 위해, 주어진 데이터를 여러 번 반복하여 나누고 학습과 평가를 수행함으로써, 모델의 성능을 더 안정적이고 신뢰성 있게 평가하는 방법론입니다.

---

### 1. K-폴드 교차 검증 (K-Fold Cross-Validation)

K-폴드 교차 검증은 가장 널리 사용되는 교차 검증 기법입니다.

**동작 원리:**
1.  **분할 (Split):** 전체 훈련 데이터셋을 **K개**의 동등한 크기를 가진 부분집합, 즉 **폴드(Fold)**로 나눕니다. (보통 K=5 또는 K=10을 많이 사용합니다.)
2.  **반복 학습 및 평가:**
    - 첫 번째 폴드를 **검증 세트(Validation Set)**로 사용하고, 나머지 K-1개의 폴드를 **훈련 세트**로 사용하여 모델을 학습시키고 성능을 평가합니다.
    - 두 번째 폴드를 검증 세트로 사용하고, 나머지 K-1개의 폴드를 훈련 세트로 사용하여 두 번째 평가를 수행합니다.
    - 이 과정을 K번 반복하여, 모든 폴드가 한 번씩 검증 세트로 사용되도록 합니다.
3.  **최종 성능:** K번의 평가를 통해 얻은 K개의 성능 지표(예: 정확도)의 **평균**을 계산하여, 모델의 최종적인 일반화 성능으로 삼습니다.

![K-Fold Cross-Validation](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)
*(이미지 출처: scikit-learn.org)*

**장점:**
- 모든 데이터가 훈련과 검증에 한 번씩 사용되므로, 데이터를 더 효율적으로 활용할 수 있습니다.
- 단 한 번의 분할로 평가하는 것보다 모델의 성능을 더 안정적이고 신뢰성 있게 추정할 수 있습니다.

---

### 2. 계층적 K-폴드 교차 검증 (Stratified K-Fold Cross-Validation)

분류(Classification) 문제에서 데이터의 클래스 분포가 불균형할 경우, 일반적인 K-폴드 방식은 문제가 될 수 있습니다. 특정 폴드에 특정 클래스의 데이터가 몰려서 생성될 수 있기 때문입니다.

**계층적 K-폴드 교차 검증**은 이러한 문제를 해결하기 위해, 각 폴드의 클래스 비율이 원본 데이터셋의 클래스 비율과 동일하도록 **계층적(stratified)**으로 데이터를 분할합니다.

- **예시:** 원본 데이터셋에 A 클래스가 70%, B 클래스가 30% 있다면, 생성되는 모든 폴드에도 A와 B가 약 7:3의 비율로 포함되도록 샘플링합니다.
- **적용:** 분류 문제, 특히 데이터 불균형이 심한 경우에는 반드시 계층적 K-폴드 교차 검증을 사용하는 것이 권장됩니다.

---

### 3. 교차 검증의 활용

- **모델 성능 평가:** 최종 모델의 일반화 성능을 신뢰성 있게 측정하는 데 사용됩니다.
- **하이퍼파라미터 튜닝:** `GridSearchCV`와 같은 도구는 교차 검증을 기반으로 여러 하이퍼파라미터 조합의 성능을 평가하여, 최적의 하이퍼파라미터 조합을 찾아냅니다. 교차 검증을 통해 특정 데이터 분할에만 과대적합되는 하이퍼파라미터가 선택되는 것을 방지합니다.

교차 검증은 계산 비용이 더 많이 든다는 단점이 있지만, 모델의 성능을 더 객관적으로 평가하고 일반화 성능을 높이기 위한 필수적인 과정입니다.
