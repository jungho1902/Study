# 비디오 분석 (Video Analysis)

**비디오 분석(Video Analysis)** 또는 **비디오 이해(Video Understanding)**는 컴퓨터 비전의 한 분야로, 비디오 데이터에 포함된 시각적, 시간적 정보를 종합적으로 분석하여 의미 있는 정보를 추출하는 것을 목표로 합니다. 정적인 이미지를 다루는 것과 달리, 비디오는 시간의 흐름에 따른 동적인 변화(움직임, 상호작용 등)를 포함하고 있어 더 복잡하고 도전적인 과제들을 다룹니다.

## 1. 비디오 데이터의 특징

- **시간적 정보 (Temporal Information):** 비디오는 여러 개의 이미지 프레임(frame)이 연속적으로 이어진 시퀀스(sequence)입니다. 따라서 프레임 간의 관계, 즉 시간의 흐름에 따른 변화가 중요한 정보를 담고 있습니다.
- **공간적 정보 (Spatial Information):** 각 프레임 자체는 하나의 이미지이므로, 이미지 내의 객체, 장면 등 공간적인 정보를 포함합니다.
- **대용량 데이터:** 비디오는 수많은 프레임으로 구성되어 있어 처리해야 할 데이터의 양이 매우 큽니다.

## 2. 주요 비디오 분석 과제

### 2.1. 행동 인식 (Action Recognition)

- 비디오 클립에 나타나는 사람이나 객체의 행동이 무엇인지를 분류하는 과제입니다. (예: '수영하기', '달리기', '기타 연주하기')
- 초기에는 각 프레임을 독립적으로 분석하여 그 결과를 종합하는 방식을 사용했지만, 최근에는 시간적 정보를 효과적으로 모델링하는 딥러닝 아키텍처가 주류를 이룹니다.
- **주요 아키텍처:**
  - **Two-Stream Networks:**
    - **공간 스트림 (Spatial Stream):** 단일 프레임 이미지를 입력받아 장면과 객체 정보를 학습 (CNN 기반).
    - **시간 스트림 (Temporal Stream):** 연속된 프레임 간의 움직임 정보인 **광학 흐름(Optical Flow)**을 입력받아 동작을 학습 (CNN 기반).
    - 두 스트림의 결과를 나중에 결합하여 최종 행동을 예측합니다.
  - **3D CNN (C3D, I3D):**
    - 2D CNN의 합성곱 필터를 3D로 확장하여, 공간(가로, 세로)뿐만 아니라 시간 차원까지 한 번에 처리하는 방식입니다.
    - `(width, height, time)`의 3D 볼륨을 입력으로 받아 시공간 특징(spatio-temporal features)을 직접 학습합니다.
  - **Vision Transformer (ViT) 기반 모델:**
    - 비디오를 여러 개의 패치(patch)로 나누고, 이를 트랜스포머에 입력하여 프레임 간의 장기적인 관계(long-range dependencies)를 효과적으로 모델링합니다. (예: TimeSformer, ViViT)

### 2.2. 비디오 객체 추적 (Video Object Tracking)

- 비디오의 첫 프레임에서 주어진 특정 객체를 이후의 모든 프레임에서 지속적으로 따라가며 위치를 찾아내는 과제입니다.
- **주요 접근 방식:**
  - **상관 필터 기반 (Correlation Filter-based):** 추적하려는 객체의 템플릿(template)을 만들고, 다음 프레임에서 이 템플릿과 가장 상관관계가 높은 영역을 찾는 방식으로 빠르게 작동합니다.
  - **딥러닝 기반 (Siamese Networks):**
    - 샴 네트워크(Siamese Network)는 두 개의 동일한 CNN으로 구성됩니다.
    - 하나의 CNN은 첫 프레임의 타겟 객체 특징을 추출하고, 다른 CNN은 검색 대상 프레임의 후보 영역 특징을 추출합니다.
    - 두 특징 벡터 간의 유사도를 계산하여 가장 유사한 영역을 타겟의 다음 위치로 예측합니다.

### 2.3. 비디오 분할 (Video Segmentation)

- 이미지 분할을 비디오로 확장한 개념으로, 비디오의 모든 프레임에 대해 각 픽셀을 의미 있는 클래스로 분할합니다.
- **Video Semantic Segmentation:** 각 픽셀을 '사람', '자동차' 등 의미론적 클래스로 분할합니다.
- **Video Instance Segmentation:** 개별 객체 인스턴스까지 구분하여 분할합니다.
- 시간적 일관성(temporal consistency)을 유지하는 것이 중요합니다. 즉, 프레임이 바뀌어도 같은 객체는 동일한 ID와 색상으로 유지되어야 합니다.

### 2.4. 기타 과제

- **행동 탐지 (Action Detection / Localization):** 비디오 전체에서 특정 행동이 '언제' 시작하고 끝나는지 시간적 위치를 찾아냅니다.
- **비디오 캡셔닝 (Video Captioning):** 비디오의 내용을 설명하는 문장을 생성합니다.
- **미래 프레임 예측 (Future Frame Prediction):** 주어진 비디오 프레임들을 바탕으로 앞으로 일어날 장면을 예측하여 생성합니다.

비디오 분석 기술은 CCTV 보안, 스포츠 분석, 자율주행, 콘텐츠 검색 및 추천 등 다양한 분야에서 활용되고 있습니다.
