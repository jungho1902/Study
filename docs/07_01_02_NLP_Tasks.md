# 주요 NLP 과제 (Major NLP Tasks)

자연어 처리(NLP)는 인간의 언어를 컴퓨터가 이해하고 처리하게 하는 인공지능의 한 분야로, 다양한 세부 과제들로 구성됩니다. 최신 딥러닝 모델(예: BERT, GPT)의 발전으로 이러한 과제들의 성능이 크게 향상되었습니다.

## 1. 감성 분석 (Sentiment Analysis)

**감성 분석**은 텍스트에 나타난 감정, 의견, 태도 등을 분석하여 긍정, 부정, 중립 등과 같은 극성(polarity)을 판별하는 과제입니다.

- **주요 응용 분야:**
  - **제품 및 서비스 리뷰 분석:** 고객 피드백을 자동으로 분석하여 제품 개선에 활용
  - **소셜 미디어 모니터링:** 특정 브랜드나 이벤트에 대한 대중의 반응 파악
  - **여론 조사:** 정치적, 사회적 이슈에 대한 여론 동향 분석
- **접근 방식:**
  - **어휘 기반:** 긍정/부정 단어 사전을 구축하여 텍스트 내 단어들의 감성 점수를 합산
  - **머신러닝/딥러닝:** 레이블된 데이터를 사용하여 지도 학습 기반의 분류 모델(예: Logistic Regression, LSTM, BERT)을 훈련

## 2. 개체명 인식 (Named Entity Recognition, NER)

**개체명 인식**은 텍스트에서 인명(Person), 기관명(Organization), 지명(Location), 날짜, 시간 등과 같이 고유한 의미를 갖는 개체(entity)를 식별하고 분류하는 과제입니다.

- **주요 응용 분야:**
  - **정보 추출:** 뉴스 기사에서 핵심 인물, 장소, 기관 정보 추출
  - **챗봇 및 Q&A 시스템:** 사용자의 질문에서 중요한 키워드(예: "서울 날씨 알려줘"에서 '서울'과 '날씨')를 파악
  - **이력서 분석:** 지원자의 이름, 학교, 경력 등을 자동으로 추출
- **접근 방식:**
  - 주로 **토큰 분류(Token Classification)** 문제로 접근하며, 각 토큰이 어떤 개체명에 속하는지(또는 속하지 않는지)를 예측합니다.
  - BIO(Beginning, Inside, Outside) 태깅 스킴이 널리 사용됩니다.
  - 딥러닝 모델로는 Bi-LSTM-CRF, BERT 등이 높은 성능을 보입니다.

## 3. 토픽 모델링 (Topic Modeling)

**토픽 모델링**은 대규모 문서 집합(corpus)에서 숨겨진 주요 주제(topic)들을 발견하는 비지도 학습 방법입니다. 문서들이 어떤 주제들로 구성되어 있는지를 확률적으로 모델링합니다.

- **주요 응용 분야:**
  - **문서 군집화 및 요약:** 대량의 뉴스 기사나 논문을 주제별로 분류
  - **콘텐츠 추천:** 사용자가 읽은 문서의 주제를 분석하여 유사한 주제의 콘텐츠 추천
- **대표적인 알고리즘:**
  - **Latent Dirichlet Allocation (LDA):** 가장 널리 사용되는 토픽 모델링 알고리즘으로, 각 문서를 '주제들의 확률 분포'로, 각 주제를 '단어들의 확률 분포'로 간주하여 모델링합니다.

## 4. 기계 번역 (Machine Translation)

**기계 번역**은 하나의 언어로 된 텍스트를 다른 언어로 자동 번역하는 과제입니다.

- **발전 과정:**
  - **규칙 기반 (RBMT):** 초기의 번역 시스템으로, 언어학적 규칙을 사람이 직접 작성
  - **통계 기반 (SMT):** 대규모 병렬 말뭉치(parallel corpus)를 이용해 번역 확률을 통계적으로 모델링
  - **신경망 기반 (NMT):** 인공 신경망(주로 RNN, Transformer)을 사용하여 번역 품질을 획기적으로 개선. **Seq2Seq** 모델이 기본 구조이며, 현재는 **어텐션 메커니즘**을 적용한 **트랜스포머**가 주류를 이룹니다.

## 5. 텍스트 요약 (Text Summarization)

**텍스트 요약**은 긴 문서의 핵심 내용을 포함하는 짧은 요약문을 생성하는 과제입니다.

- **주요 접근 방식:**
  - **추출 요약 (Extractive Summarization):** 원문에서 중요한 문장이나 구절을 **선택**하여 요약문을 구성합니다. 상대적으로 구현이 간단하고 원문의 내용을 보존하는 장점이 있습니다.
  - **추상 요약 (Abstractive Summarization):** 원문의 내용을 이해한 후, 새로운 문장을 **생성**하여 요약문을 만듭니다. 인간이 요약하는 방식과 유사하며, 더 자연스럽고 간결한 요약이 가능하지만 구현이 더 복잡합니다. (예: 트랜스포머 기반의 T5, BART 모델)

## 6. 질의응답 시스템 (Question Answering, QA)

**질의응답 시스템**은 사용자의 질문에 대해 주어진 문맥(context)이나 방대한 지식 베이스에서 정확한 답변을 찾아 제공하는 과제입니다.

- **주요 유형:**
  - **추출적 QA (Extractive QA):** 주어진 문단이나 문서 내에서 답변에 해당하는 부분을 그대로 **추출**합니다. (예: SQuAD 데이터셋)
  - **생성적 QA (Generative QA):** 질문을 이해하고 답변을 **새롭게 생성**합니다.
  - **오픈 도메인 QA (Open-Domain QA):** 특정 문서가 주어지지 않고, 웹과 같은 방대한 정보 소스에서 답변을 찾습니다. 검색(retrieval)과 독해(reading) 능력이 모두 필요합니다.
- **최신 기술:** 딥러닝 기반의 독해 모델(Reading Comprehension)이 주로 사용되며, BERT와 같은 사전 훈련된 언어 모델을 미세 조정하여 높은 성능을 달성합니다.
