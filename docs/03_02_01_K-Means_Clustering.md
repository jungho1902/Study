# 3.2.1. K-평균 군집화 (K-Means Clustering)

**K-평균(K-Means)**은 대표적인 **비지도 학습(Unsupervised Learning)** 알고리즘 중 하나로, 주어진 데이터들을 K개의 **군집(cluster)**으로 묶는 **군집화(Clustering)** 알고리즘입니다. K-평균은 각 군집의 중심(centroid)을 기반으로 동작하며, 구현이 비교적 간단하고 여러 분야에서 널리 사용됩니다.

## 1. K-평균 알고리즘의 동작 원리

K-평균 알고리즘은 다음과 같은 순서로 동작합니다.

1.  **초기화 (Initialization)**:
    - 사용자는 미리 군집의 개수, 즉 **K값**을 정해야 합니다.
    - 데이터 공간에서 K개의 점을 무작위로 선택하여 각 군집의 초기 **중심(centroid)**으로 설정합니다.

2.  **할당 (Assignment)**:
    - 데이터셋의 모든 데이터 포인트에 대해, K개의 중심점 중 **가장 가까운 중심점**을 찾습니다.
    - 각 데이터 포인트는 가장 가까운 중심점이 속한 군집에 할당됩니다. (거리는 보통 유클리드 거리를 사용합니다.)

3.  **업데이트 (Update)**:
    - 각 군집에 할당된 모든 데이터 포인트들의 **평균**을 계산하여, 해당 군집의 중심점을 새로 업데이트합니다.
    - 이 새로운 평균 지점이 군집의 새로운 중심(centroid)이 됩니다.

4.  **반복 (Repeat)**:
    - 2번(할당)과 3번(업데이트) 과정을 계속 반복합니다.
    - 군집의 중심점이 더 이상 변하지 않거나, 사용자가 지정한 반복 횟수에 도달하면 알고리즘이 종료됩니다.

이 과정을 통해 K-평균은 각 군집 내 데이터 포인트들의 응집도(분산)를 최소화하는 방향으로 중심점을 점차 최적화해 나갑니다.

![K-Means Process](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/K-means_convergence.gif/300px-K-means_convergence.gif)
*(이미지 출처: 위키미디어)*

## 2. 최적의 K값 찾기: 엘보우 방법 (Elbow Method)

K-평균 알고리즘의 성능은 사용자가 처음에 지정하는 **K값**에 크게 좌우됩니다. 적절한 K값을 찾기 위해 가장 널리 사용되는 방법 중 하나가 **엘보우 방법(Elbow Method)**입니다.

- **WCSS (Within-Cluster Sum of Squares)**: 각 군집 내 데이터 포인트들과 군집 중심 사이의 거리 제곱의 합을 의미합니다. WCSS 값이 작을수록 군집 내 데이터들이 중심점에 잘 모여있다는 뜻입니다.
- **엘보우 방법**:
  1. K를 1부터 점차 늘려가면서 K-평균 알고리즘을 여러 번 실행하고, 각 K값에 대한 WCSS를 계산합니다.
  2. K값의 변화에 따른 WCSS 값의 변화를 그래프로 그립니다.
  3. 그래프를 보면 K값이 커질수록 WCSS는 계속 감소하지만, 어느 특정 지점부터는 감소율이 급격히 둔화됩니다. 이 지점이 마치 '팔꿈치(elbow)'처럼 꺾이는 모양을 하고 있으며, 이 지점의 K값을 최적의 군집 개수로 선택하는 방법입니다.

## 3. K-평균의 한계

K-평균은 간단하고 효율적이지만 몇 가지 중요한 한계를 가지고 있습니다.

- **초기 중심점 민감성**: 초기 중심점을 어떻게 선택하느냐에 따라 최종 군집 결과가 달라질 수 있습니다. 이를 해결하기 위해, 초기 중심점을 다르게 설정하여 알고리즘을 여러 번 실행한 후 가장 좋은 결과를 선택하는 방식을 사용합니다.
- **군집 형태 가정**: K-평균은 각 군집이 원형(spherical)이고, 크기가 비슷하며, 밀도가 균일할 것이라고 가정합니다. 따라서 길쭉하거나 비정형적인 모양의 군집, 또는 밀도가 다른 군집을 잘 찾아내지 못합니다.
- **K값 사전 지정 필요**: 군집의 개수(K)를 사용자가 미리 알고 있어야 한다는 가정이 필요합니다. 실제 문제에서는 최적의 K를 알기 어려운 경우가 많습니다.
- **이상치(Outlier)에 민감**: 이상치는 군집의 중심을 크게 왜곡시켜 군집화 성능을 저하시킬 수 있습니다.

---

## 예제 및 풀이 (Examples and Solutions)

### 예제 1: K-평균 알고리즘의 1회 반복

**문제:** 2차원 평면에 6개의 데이터 포인트 `P1(1,1), P2(1,2), P3(2,1), P4(5,5), P5(5,6), P6(6,5)`가 있습니다. K=2로 설정하고, 초기 중심점을 `C1=(1,1)`과 `C2=(5,5)`로 선택했을 때, 알고리즘의 첫 번째 반복(할당->업데이트) 후 새로운 중심점 C1'과 C2'의 위치를 계산하시오.

**풀이:**

1.  **초기 상태:**
    - 데이터: {P1, P2, P3, P4, P5, P6}
    - 중심점: C1=(1,1), C2=(5,5)

2.  **할당 (Assignment) 단계:**
    - 각 데이터 포인트와 두 중심점(C1, C2) 사이의 유클리드 거리를 계산하여 더 가까운 군집에 할당합니다.
    - **P1(1,1):** C1과의 거리가 0이므로 **군집 1**에 할당.
    - **P2(1,2):**
      - d(P2, C1) = sqrt((1-1)²+(2-1)²) = 1
      - d(P2, C2) = sqrt((1-5)²+(2-5)²) = sqrt(16+9) = 5
      - C1이 더 가까우므로 **군집 1**에 할당.
    - **P3(2,1):**
      - d(P3, C1) = sqrt((2-1)²+(1-1)²) = 1
      - d(P3, C2) = sqrt((2-5)²+(1-5)²) = sqrt(9+16) = 5
      - C1이 더 가까우므로 **군집 1**에 할당.
    - **P4(5,5):** C2와의 거리가 0이므로 **군집 2**에 할당.
    - **P5(5,6):** C2와의 거리가 1이므로 **군집 2**에 할당.
    - **P6(6,5):** C2와의 거리가 1이므로 **군집 2**에 할당.

    - **할당 결과:**
      - 군집 1: {P1(1,1), P2(1,2), P3(2,1)}
      - 군집 2: {P4(5,5), P5(5,6), P6(6,5)}

3.  **업데이트 (Update) 단계:**
    - 각 군집에 속한 데이터 포인트들의 평균을 계산하여 새로운 중심점을 찾습니다.
    - **새로운 중심점 C1':**
      - x 좌표 평균: (1+1+2)/3 = 4/3
      - y 좌표 평균: (1+2+1)/3 = 4/3
      - **C1' = (4/3, 4/3) ≈ (1.33, 1.33)**
    - **새로운 중심점 C2':**
      - x 좌표 평균: (5+5+6)/3 = 16/3
      - y 좌표 평균: (5+6+5)/3 = 16/3
      - **C2' = (16/3, 16/3) ≈ (5.33, 5.33)**

**답:**
알고리즘의 첫 번째 반복 후, 새로운 중심점은 **C1'=(1.33, 1.33)**과 **C2'=(5.33, 5.33)**이 됩니다.
이후 K-평균 알고리즘은 이 새로운 중심점을 기준으로 다시 할당과 업데이트 단계를 중심점이 더 이상 변하지 않을 때까지 반복합니다.
