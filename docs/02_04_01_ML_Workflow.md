# 머신러닝 프로젝트의 전체 과정 (The Machine Learning Workflow)

머신러닝 모델을 개발하는 것은 단순히 코드 몇 줄을 작성하는 것 이상의 체계적인 과정입니다. 성공적인 머신러닝 프로젝트는 아이디어 구상부터 실제 운영 및 유지보수까지 이어지는 **생명주기(Lifecycle)**를 가집니다. 이 전체 과정을 **머신러닝 워크플로우(ML Workflow)**라고 부릅니다.

이 워크플로우는 일반적으로 다음과 같은 단계로 구성되며, 각 단계는 서로 유기적으로 연결되어 있고 때로는 반복되기도 합니다.

---

### 1. 문제 정의 (Problem Definition)
모든 프로젝트의 가장 중요하고 첫 번째 단계입니다. 성공적인 모델은 해결하려는 문제가 명확할 때 만들어집니다.
- **비즈니스 목표 이해:** 프로젝트를 통해 달성하고자 하는 비즈니스 목표가 무엇인지 파악합니다. (예: "고객 이탈률을 10% 감소시키고 싶다.")
- **ML 문제로 변환:** 비즈니스 문제를 머신러닝 문제로 재정의합니다.
  - **지도학습? 비지도학습? 강화학습?** (예: 고객 이탈 예측 → **분류(Classification)** 문제)
  - **예측 대상 정의:** 무엇을 예측할 것인가? (예: 각 고객이 다음 달에 '이탈할지' 또는 '유지될지')
- **성공 지표 설정:** 모델의 성능을 어떻게 측정할지, 프로젝트의 성공을 어떻게 판단할지 구체적인 지표를 설정합니다. (예: 기술적 지표 - `정확도(Accuracy)`, `F1-Score`; 비즈니스 지표 - `실제 이탈 방지 비용 절감액`)

### 2. 데이터 수집 (Data Collection)
정의된 문제를 해결하는 데 필요한 데이터를 모으는 단계입니다. 데이터의 질과 양이 모델의 성능을 결정합니다.
- **데이터 소스:** 내부 데이터베이스, 로그 파일, API, 외부 공개 데이터, 웹 스크래핑 등 다양한 경로를 통해 데이터를 수집합니다.
- **필요 데이터 정의:** 어떤 정보가 예측에 도움이 될지 가설을 세우고 관련 데이터를 수집합니다. (예: 고객의 나이, 가입 기간, 월평균 구매액, 최근 접속일 등)

### 3. 데이터 탐색 및 전처리 (Data Exploration and Preprocessing)
수집된 원본 데이터(Raw Data)를 모델이 학습할 수 있는 깨끗하고 정제된 형태로 만드는 과정입니다. 종종 프로젝트 시간의 60~70% 이상을 차지할 만큼 중요하고 손이 많이 가는 단계입니다.
- **탐색적 데이터 분석 (EDA, Exploratory Data Analysis):** 데이터를 시각화하거나 통계치를 계산하며 데이터에 대한 이해를 높입니다. 패턴, 이상치, 변수 간의 관계 등을 파악합니다.
- **데이터 정제 (Data Cleaning):**
  - **결측치 처리:** 비어있는 값을 채우거나(평균, 중앙값 등) 해당 데이터를 제거합니다.
  - **이상치 처리:** 비정상적으로 튀는 값을 탐지하고 처리합니다.
- **특성 공학 (Feature Engineering):**
  - 기존 특성을 조합하거나 변형하여 모델의 성능을 높일 수 있는 새로운 특성을 만듭니다. (예: '가입일' → '총 서비스 이용 기간')
  - 범주형 데이터를 숫자형으로 변환합니다. (원-핫 인코딩 등)
  - **데이터 정규화/표준화:** 특성들의 값의 범위를 비슷하게 맞춰 모델이 더 안정적으로 학습하도록 합니다.
- **데이터 분할:** 전체 데이터를 **훈련(Training)용, 검증(Validation)용, 테스트(Test)용**으로 분할합니다.

### 4. 모델 선택 (Model Selection)
정의된 문제 유형과 데이터의 특성에 맞는 적절한 머신러닝 알고리즘을 선택합니다.
- 처음에는 여러 모델(예: 로지스틱 회귀, 결정 트리, 서포트 벡터 머신 등)을 후보로 선택하고, 간단한 테스트를 통해 가장 성능이 좋은 모델을 추려나가는 방식을 많이 사용합니다.

### 5. 모델 훈련 (Model Training)
선택된 모델에 **훈련(Training) 데이터**를 입력하여 패턴을 학습시키는 단계입니다. 이 과정에서 모델은 내부 파라미터를 최적화하여 입력과 출력 간의 관계를 가장 잘 설명하는 방법을 찾아냅니다.

### 6. 모델 평가 (Model Evaluation)
학습된 모델이 얼마나 좋은 성능을 내는지 평가하는 단계입니다.
- **핵심:** 모델이 한 번도 보지 못한 **테스트(Test) 데이터**를 사용하여 평가해야 합니다. 이는 모델이 새로운 데이터에 대해 얼마나 잘 일반화되는지를 측정하기 위함입니다.
- 1단계에서 정의했던 평가 지표(예: 정확도, 정밀도, 재현율, F1-Score, RMSE 등)를 사용하여 모델의 성능을 객관적으로 측정합니다.

### 7. 하이퍼파라미터 튜닝 (Hyperparameter Tuning)
모델의 성능을 마지막 한 방울까지 끌어올리기 위해 최적의 하이퍼파라미터 조합을 찾는 과정입니다.
- **하이퍼파라미터란?** 모델이 학습을 통해 찾는 파라미터가 아니라, 개발자가 직접 설정해줘야 하는 값입니다. (예: 학습률, k-NN의 k값, 결정 트리의 최대 깊이)
- **검증(Validation) 데이터**를 사용하여 여러 하이퍼파라미터 조합으로 모델을 테스트하고, 가장 높은 성능을 보인 조합을 선택합니다. (Grid Search, Random Search 등의 기법 사용)

### 8. 모델 배포 및 모니터링 (Deployment and Monitoring)
최종적으로 완성된 모델을 실제 서비스나 시스템에 통합하여 사용자가 활용할 수 있도록 하는 단계입니다.
- **배포 (Deployment):** 학습된 모델을 API 서버 형태로 만들거나, 애플리케이션에 내장하는 등의 방법으로 실제 환경에 적용합니다.
- **모니터링 및 유지보수:** 배포된 모델의 성능을 지속적으로 추적합니다. 시간이 지남에 따라 데이터의 패턴이 변해(Drift) 모델 성능이 저하될 수 있으므로, 주기적으로 새로운 데이터로 모델을 재학습하고 업데이트하는 과정이 필요합니다.

이러한 워크플로우는 한 번에 끝나는 선형적인 과정이 아니라, 평가 및 모니터링 단계의 피드백을 통해 다시 앞 단계로 돌아가 개선하는 **반복적이고 순환적인(Iterative & Cyclical)** 특징을 가집니다.
