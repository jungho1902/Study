# 주성분 분석 (Principal Component Analysis, PCA) - 기초 개념

주성분 분석(PCA)은 가장 널리 사용되는 **차원 축소(dimensionality reduction)** 기법 중 하나입니다. PCA는 데이터에 분산이 가장 큰 방향(주성분)을 찾고, 그 방향으로 데이터를 투영하여 원래 데이터의 특징을 최대한 유지하면서 데이터의 차원을 줄입니다.

---

### 1. PCA의 목표와 원리

고차원 데이터(많은 특성을 가진 데이터)는 분석과 시각화가 어렵고, '차원의 저주(curse of dimensionality)' 문제로 인해 모델 성능이 저하될 수 있습니다. PCA는 이러한 문제를 해결하기 위해 사용됩니다.

**핵심 원리:**
PCA는 데이터의 **분산(variance)**을 최대한 보존하는 새로운 축(주성분)을 찾습니다.
- **첫 번째 주성분 (PC1):** 데이터의 분산이 가장 큰 방향을 나타내는 축.
- **두 번째 주성분 (PC2):** PC1에 직교하면서, 나머지 분산 중에서 가장 큰 분산을 갖는 방향의 축.
- ...이하 반복.

이 새로운 축들은 서로 직교(orthogonal)하며, 원본 데이터의 선형 조합으로 만들어집니다. PCA는 이 주성분들 중 처음 몇 개(예: PC1, PC2)만을 선택하여 데이터를 저차원 공간에 표현함으로써 차원을 축소합니다.

---

### 2. PCA와 선형대수 개념의 연결

PCA는 이전에 다룬 선형대수 개념들과 깊이 연관되어 있습니다.
- **공분산 행렬 (Covariance Matrix):** 데이터의 각 특성들이 어떻게 함께 변하는지를 나타내는 행렬입니다. PCA는 이 공분산 행렬을 사용해 데이터의 분산 구조를 파악합니다.
- **고유값과 고유벡터 (Eigenvalues & Eigenvectors):** 공분산 행렬에 대한 고유값 분해(eigendecomposition)가 PCA의 핵심입니다.
  - **고유벡터:** 데이터의 분산이 큰 방향, 즉 **주성분(Principal Components)**의 방향을 나타냅니다.
  - **고유값:** 해당 고유벡터 방향으로 데이터가 가진 **분산의 크기**를 나타냅니다. 큰 고유값일수록 더 중요한 주성분입니다.

---

### 3. PCA의 절차

PCA는 다음과 같은 단계로 수행됩니다.

1.  **데이터 표준화 (Standardization):** 각 특성(feature)의 평균을 0, 분산을 1로 만듭니다. 이는 각 특성의 스케일이 달라서 발생하는 문제를 방지합니다.
2.  **공분산 행렬 계산 (Covariance Matrix Calculation):** 표준화된 데이터로부터 공분산 행렬을 계산합니다.
3.  **고유값 분해 (Eigendecomposition):** 공분산 행렬의 고유값과 고유벡터를 계산합니다.
4.  **주성분 선택 (Select Principal Components):** 계산된 고유값을 내림차순으로 정렬하고, 가장 큰 고유값에 해당하는 고유벡터(주성분)를 원하는 차원의 수(k)만큼 선택합니다.
5.  **데이터 변환 (Transform Data):** 원본 데이터를 선택된 k개의 주성분으로 이루어진 새로운 축 공간으로 투영(projection)하여 k차원의 새로운 데이터 행렬을 생성합니다.

---

## 예제 및 풀이 (Examples and Solutions)

### 예제 1: PCA의 개념적 예

**문제:** 학생들의 '수학 점수'와 '물리 점수'라는 2차원 데이터가 있다고 가정합시다. 이 데이터를 PCA를 사용하여 1차원으로 축소하는 과정을 개념적으로 설명하시오.

**풀이:**

1.  **데이터 분포:** '수학 점수'를 x축, '물리 점수'를 y축으로 하는 2D 좌표 평면에 학생들의 점수 데이터를 점으로 나타냅니다. 수학과 물리 점수 사이에 양의 상관관계가 있다면, 점들은 대략 우상향하는 타원 형태로 분포할 것입니다.

2.  **주성분 찾기:**
    - **PC1 (첫 번째 주성분):** 데이터가 가장 길게, 즉 분산이 가장 큰 방향으로 축을 긋습니다. 이 축이 바로 PC1입니다. 이 축은 데이터의 전반적인 '학업 성취도' 경향을 나타낼 가능성이 높습니다.
    - **PC2 (두 번째 주성분):** PC1에 수직인 방향으로 축을 긋습니다. 이 축이 PC2가 됩니다.

3.  **차원 축소:**
    - 우리는 2차원 데이터를 1차원으로 축소하기로 했으므로, 가장 중요한 축인 PC1만 선택합니다.
    - 모든 데이터 포인트들을 PC1 축 위로 직교 투영(orthogonal projection)합니다. 즉, 각 점에서 PC1 축에 수선의 발을 내립니다.

4.  **결과:**
    - 원래 2차원 좌표 `(수학 점수, 물리 점수)`를 가졌던 각 학생의 데이터는 이제 PC1 축 위의 단일 값(스칼라)으로 표현됩니다.
    - 이 단일 값은 각 학생의 '주성분 점수(principal component score)'가 되며, 원래의 두 과목 점수 정보를 가장 잘 요약하는 하나의 '종합 학업 성취도' 지표로 해석될 수 있습니다.
    - 이 과정을 통해 데이터는 1차원으로 성공적으로 축소되었습니다.
