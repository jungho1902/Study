# 6.2. 데이터 및 피처 관리 (Data and Feature Management)

MLOps 파이프라인에서 데이터와 피처는 모델의 성능을 좌우하는 가장 중요한 자산입니다. 이들을 체계적으로 관리하는 것은 성공적인 머신러닝 시스템의 핵심입니다. 이 문서에서는 데이터 파이프라인, 데이터 버전 관리, 그리고 피처 스토어에 대해 다룹니다.

---

### 1. 데이터 파이프라인 (Data Pipeline)

데이터 파이프라인은 여러 소스에서 원시 데이터를 수집하여 정제하고, 변환한 후, 최종 목적지(예: 데이터 웨어하우스, 모델 학습 시스템)로 옮기는 일련의 자동화된 프로세스입니다.

#### ETL (Extract, Transform, Load) - 추출, 변환, 적재
ETL은 전통적인 데이터 처리 방식으로, 다음과 같은 순서로 진행됩니다.
1.  **Extract (추출):** 데이터베이스, 로그 파일, 외부 API 등 다양한 소스에서 데이터를 추출합니다.
2.  **Transform (변환):** 추출된 데이터를 특정 목적에 맞게 정제, 결합, 집계, 정규화하는 등 비즈니스 로직을 적용하여 변환합니다. 이 변환 과정은 별도의 스테이징(Staging) 서버에서 수행됩니다.
3.  **Load (적재):** 변환된 데이터를 최종 목적지인 데이터 웨어하우스(Data Warehouse)에 적재합니다.

-   **특징:** 데이터가 이미 정제되고 구조화된 상태로 저장되므로 분석 및 쿼리 속도가 빠릅니다. 하지만 새로운 분석 요구사항이 생길 때마다 변환 로직을 다시 설계해야 하는 유연성 부족이 단점입니다.

#### ELT (Extract, Load, Transform) - 추출, 적재, 변환
ELT는 클라우드 기반의 최신 데이터 처리 방식으로, 순서가 다릅니다.
1.  **Extract (추출):** 소스 시스템에서 데이터를 추출합니다.
2.  **Load (적재):** 추출된 원시 데이터(raw data)를 거의 그대로 데이터 레이크(Data Lake)와 같은 대용량 저장소에 먼저 적재합니다.
3.  **Transform (변환):** 데이터 분석가나 사이언티스트가 필요할 때, 데이터 레이크에 저장된 데이터를 가져와 다양한 방식으로 변환 및 가공합니다.

-   **특징:** 원시 데이터를 그대로 보관하므로 데이터 손실이 없으며, 다양한 목적에 맞게 유연하게 데이터를 변환할 수 있습니다. 데이터 저장 비용이 저렴해지면서 널리 사용되고 있습니다.

---

### 2. 데이터 버전 관리 (Data Version Control, DVC)

데이터 버전 관리(DVC)는 Git과 같은 버전 관리 시스템의 원칙을 데이터셋과 머신러닝 모델에 적용하는 도구 및 프로세스입니다.

#### 왜 필요한가?
-   **재현성:** 특정 시점에 어떤 데이터로 모델을 학습시켰는지 정확히 재현할 수 있습니다. "어제는 잘 됐는데 오늘은 왜 안 되지?"와 같은 문제를 방지합니다.
-   **실험 추적:** 다양한 버전의 데이터셋으로 실험한 결과를 체계적으로 추적하고 비교할 수 있습니다.
-   **협업:** 팀원들이 동일한 데이터 버전을 사용하여 일관된 환경에서 작업할 수 있습니다.

#### DVC의 작동 방식
Git은 대용량 파일(GB/TB 단위의 데이터셋)을 직접 관리하기에 적합하지 않습니다. DVC는 이 문제를 다음과 같이 해결합니다.
1.  **메타데이터만 Git으로 관리:** DVC는 실제 데이터 파일 대신, 데이터에 대한 정보(해시값, 저장 위치 등)를 담은 작은 `.dvc` 메타데이터 파일을 생성합니다. 이 파일은 Git으로 버전 관리합니다.
2.  **실제 데이터는 별도 저장:** 실제 데이터 파일은 클라우드 스토리지(S3, Google Cloud Storage 등)나 로컬 서버와 같은 원격 저장소에 저장됩니다.
3.  **데이터와 코드 연결:** Git으로 특정 버전의 코드를 체크아웃하면, DVC는 해당 코드와 연결된 버전의 데이터를 원격 저장소에서 가져와 동기화해줍니다.

-   **대표적인 도구:** `DVC (Data Version Control)`가 가장 널리 쓰이는 오픈소스 도구입니다.

---

### 3. 피처 스토어 (Feature Store)

피처 스토어는 머신러닝 모델을 위한 피처(Feature)를 중앙에서 관리하고 서빙하는 시스템입니다. 피처의 생성, 저장, 공유, 재사용을 위한 '단일 진실 공급원(Single Source of Truth)' 역할을 합니다.

#### 왜 필요한가?
-   **피처 중복 개발 방지:** 여러 팀이나 프로젝트에서 동일한 피처(예: 사용자의 최근 30일 구매액)를 중복으로 계산하는 비효율을 막습니다.
-   **학습/서빙 편향(Training/Serving Skew) 해결:** 모델 학습 시점과 실제 예측 시점의 피처 계산 방식이 달라 발생하는 성능 저하 문제를 방지합니다. 피처 스토어는 동일한 로직으로 피처를 계산하여 온라인(실시간 예측)과 오프라인(모델 학습) 환경 모두에 제공합니다.
-   **피처 발견 및 재사용:** 데이터 사이언티스트들이 기존에 만들어진 유용한 피처들을 쉽게 발견하고 재사용하여 모델 개발 속도를 높일 수 있습니다.

#### 피처 스토어의 주요 구성 요소
1.  **피처 생성 및 변환 (Feature Engineering):** 원시 데이터로부터 피처를 계산하는 파이프라인입니다. (주로 배치 작업으로 실행)
2.  **온라인 스토어 (Online Store):** 실시간 예측 서빙을 위해 낮은 지연 시간(low-latency)으로 피처를 제공하는 저장소입니다. (예: Redis, DynamoDB)
3.  **오프라인 스토어 (Offline Store):** 모델 학습 및 분석을 위해 대용량의 피처 데이터를 저장하는 저장소입니다. (예: S3, BigQuery, Snowflake)
4.  **피처 레지스트리 (Feature Registry):** 피처의 정의, 메타데이터(소유자, 버전, 설명 등), 통계 정보를 저장하고 검색할 수 있는 중앙 카탈로그입니다.

-   **대표적인 솔루션:** `Feast`, `Tecton`, `Databricks Feature Store`, `Vertex AI Feature Store` 등이 있습니다.
