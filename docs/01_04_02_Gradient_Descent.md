# 경사 하강법 (Gradient Descent)

**경사 하강법(Gradient Descent)**은 머신러닝에서 모델의 비용 함수(Cost Function)를 최소화하기 위해 가장 널리 사용되는 1차(first-order) 반복적 최적화 알고리즘입니다. 함수의 기울기(gradient)를 이용하여 파라미터를 점진적으로 업데이트하면서 최저점에 도달하는 방식입니다.

---

### 1. 경사 하강법의 원리

어떤 함수의 최솟값을 찾는 과정을 '산을 내려오는 것'에 비유할 수 있습니다.
- **현재 위치:** 현재 모델의 파라미터($`\theta`$) 값.
- **높이:** 현재 파라미터에서의 비용 함수($`J(\theta)`$) 값.
- **내려가는 방향:** 현재 위치에서 가장 가파른 내리막길의 방향. 이 방향은 **그래디언트($`\nabla J(\theta)`$)의 반대 방향**입니다.

경사 하강법은 현재 위치에서 그래디언트를 계산한 뒤, 그 반대 방향으로 정해진 보폭(learning rate)만큼 이동하는 과정을 반복하여 함수의 최솟값(local minimum)을 찾아갑니다.

**파라미터 업데이트 규칙:**
$`\theta_{new} := \theta_{old} - \eta \nabla J(\theta_{old})`$

- $`\theta`$: 업데이트할 모델 파라미터 벡터 (예: 가중치 `w`와 편향 `b`).
- $`:=`$: 값의 업데이트를 의미합니다.
- $`\eta`$ (에타): **학습률(Learning Rate)**. 파라미터를 업데이트할 때 이동할 보폭의 크기를 결정합니다.
  - 학습률이 너무 크면 최저점을 지나쳐 발산할 수 있고, 너무 작으면 학습 속도가 매우 느려집니다. 적절한 학습률을 선택하는 것이 중요합니다.
- $`\nabla J(\theta)`$: 비용 함수 $`J`$에 대한 파라미터 $`\theta`$의 그래디언트.

---

### 2. 경사 하강법의 종류

그래디언트를 계산할 때 사용하는 훈련 데이터의 양에 따라 세 가지 주요 변형이 있습니다.

#### 가. 배치 경사 하강법 (Batch Gradient Descent)

- **방법:** 한 번의 파라미터 업데이트를 위해 **전체 훈련 데이터셋**을 사용하여 그래디언트를 계산합니다.
- **장점:**
  - 전체 데이터의 정보를 사용하므로, 그래디언트가 안정적이고 최저점을 향해 부드럽게 수렴합니다.
- **단점:**
  - 데이터셋이 매우 클 경우, 한 번의 업데이트에 많은 계산량이 필요하여 속도가 매우 느립니다.
  - 대규모 데이터셋에서는 메모리 문제를 일으킬 수 있습니다.

#### 나. 확률적 경사 하강법 (Stochastic Gradient Descent, SGD)

- **방법:** 파라미터를 업데이트할 때마다 훈련 데이터셋에서 **무작위로 선택된 하나의 데이터 포인트**만을 사용하여 그래디언트를 계산합니다.
- **장점:**
  - 업데이트 속도가 매우 빠릅니다.
  - 그래디언트의 변동성(noise)이 심하여, 오히려 지역 최저점(local minima)을 탈출하고 더 좋은 최저점을 찾을 가능성이 있습니다.
- **단점:**
  - 그래디언트가 불안정하여 수렴 과정이 매우 불안정하고 진동이 심합니다.
  - 최저점에 정확히 수렴하지 않고 주변을 맴돌 수 있습니다.

#### 다. 미니배치 경사 하강법 (Mini-batch Gradient Descent)

- **방법:** 배치(Batch)와 확률적(Stochastic) 경사 하강법의 절충안. 전체 데이터셋을 **'미니배치(mini-batch)'**라고 불리는 여러 개의 작은 묶음으로 나눈 뒤, 각 미니배치에 대해 그래디언트를 계산하여 파라미터를 업데이트합니다.
- **장점:**
  - SGD의 빠른 업데이트 속도와 배치 경사 하강법의 안정적인 수렴의 장점을 모두 취할 수 있습니다.
  - GPU와 같은 하드웨어의 병렬 처리를 효율적으로 활용할 수 있어 현대 딥러닝에서 가장 표준적으로 사용되는 방법입니다.
- **일반적인 미니배치 크기:** 32, 64, 128, 256 등 2의 거듭제곱을 사용하는 경우가 많습니다.

**요약:**
| 종류 | 그래디언트 계산 단위 | 속도 | 안정성 | 메모리 효율 |
|---|---|---|---|---|
| **배치** | 전체 데이터 | 느림 | 높음 | 낮음 |
| **확률적(SGD)** | 1개 데이터 | 빠름 | 낮음 | 높음 |
| **미니배치** | n개 데이터 | 중간 | 중간 | 높음 |
