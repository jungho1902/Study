# 볼록 최적화 (Convex Optimization)

**볼록 최적화(Convex Optimization)**는 최적화 문제의 한 종류로, 특정 조건(볼록성)을 만족하여 문제를 비교적 '쉽게' 풀 수 있는 경우를 다룹니다. 볼록 최적화 문제에서는 **지역 최적해(local minimum)가 항상 전역 최적해(global minimum)**임이 보장되기 때문에, 최적화 알고리즘이 해를 찾았을 때 그것이 가장 좋은 해라고 확신할 수 있습니다.

---

### 1. 볼록 집합과 볼록 함수

볼록 최적화를 이해하기 위해서는 먼저 볼록 집합과 볼록 함수를 알아야 합니다.

#### 가. 볼록 집합 (Convex Set)
어떤 집합 내의 임의의 두 점을 선택하여 선분으로 이었을 때, 그 선분 위의 모든 점이 항상 원래 집합에 포함된다면, 그 집합은 **볼록 집합**입니다.
- **예시:** 원, 사각형, 삼각형은 볼록 집합입니다.
- **예시 (반대):** 초승달 모양, 별 모양은 집합 내의 두 점을 이은 선분이 집합 밖으로 나가는 경우가 있으므로 볼록 집합이 아닙니다.

#### 나. 볼록 함수 (Convex Function)
정의역(domain)이 볼록 집합인 함수 $`f`$에서, 그래프 위의 임의의 두 점을 잇는 선분이 항상 함수 그래프보다 위쪽이나 같은 곳에 위치할 때, 이 함수를 **볼록 함수**라고 합니다.
- **형태:** 아래로 볼록한 '그릇' 모양을 가집니다.
- **수학적 정의:** $`f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda)y`$ (단, $`0 \le \lambda \le 1`$)
- **중요한 특징:** 볼록 함수의 2차 미분(Hessian)은 항상 양수 또는 0입니다 ($`f''(x) \ge 0`$).

### 2. 볼록 최적화 문제

다음 두 가지 조건을 만족하는 최적화 문제를 **볼록 최적화 문제**라고 합니다.
1.  **목적 함수(Objective function)가 볼록 함수**여야 합니다.
2.  **해결책의 탐색 공간(Feasible set)이 볼록 집합**이어야 합니다. (제약 조건들이 볼록 집합을 정의해야 함)

### 3. 왜 볼록 최적화가 중요한가?

- **유일한 최적해 보장:** 볼록 최적화 문제에서는 **모든 지역 최적해가 곧 전역 최적해**입니다. 즉, 경사 하강법과 같은 알고리즘을 사용하여 어떤 최저점을 찾았을 때, 그 점이 문제 전체에서 가장 좋은 해임을 보장할 수 있습니다. 수많은 나쁜 지역 최저점(bad local minima)에 빠질 위험이 없습니다.

- **효율적인 해결:** 볼록 최적화 문제는 효율적으로 최적해를 찾는 알고리즘들이 많이 개발되어 있습니다.

### 4. 머신러닝에서의 볼록/비볼록 문제

- **볼록 최적화 문제의 예:**
  - **선형 회귀 (Linear Regression):** 비용 함수인 평균 제곱 오차(MSE)는 볼록 함수입니다.
  - **로지스틱 회귀 (Logistic Regression):** 비용 함수인 로그 손실(Log Loss)은 볼록 함수입니다.
  - **서포트 벡터 머신 (Support Vector Machines, SVM)**

  이러한 모델들은 항상 전역 최적해를 찾을 수 있기 때문에, 안정적이고 예측 가능한 학습 결과를 보입니다.

- **비볼록 최적화 (Non-convex Optimization) 문제의 예:**
  - **딥러닝 (Deep Learning):** 대부분의 심층 신경망의 손실 함수는 매우 복잡하고 수많은 파라미터를 가진 비볼록 함수입니다. 이는 손실 공간에 수많은 지역 최적점과 안장점(saddle point)이 존재함을 의미합니다.
  - 이 때문에 딥러닝에서는 경사 하강법이 전역 최적해를 찾는 것을 보장하지 못합니다. 그럼에도 불구하고, Adam, RMSprop과 같은 발전된 최적화 알고리즘과 적절한 초기화 기법 등을 통해 경험적으로 매우 좋은 성능을 내는 지역 최적해를 효과적으로 찾아냅니다.
