# 최대 가능도 추정 (Maximum Likelihood Estimation, MLE)

**최대 가능도 추정(Maximum Likelihood Estimation, MLE)**, 또는 최대우도법은 주어진 데이터(표본)를 바탕으로, 이 데이터가 추출되었을 가능성이 가장 높은 모집단의 **모수(Parameter)**를 추정하는 방법입니다.

즉, "어떤 모수 `θ`가 주어졌을 때 이 데이터가 관찰될 확률"을 나타내는 **가능도(Likelihood)**를 최대로 만드는 모수 `θ`를 찾는 것이 MLE의 목표입니다.

MLE는 머신러닝에서 모델의 가중치(weight)나 파라미터를 학습하는 데 매우 널리 사용되는 원리입니다. 예를 들어, 로지스틱 회귀(Logistic Regression)는 MLE를 사용하여 데이터 포인트를 가장 잘 분류하는 파라미터를 찾습니다.

## 1. 확률(Probability) vs. 가능도(Likelihood)

두 용어는 종종 혼용되지만, 통계에서는 명확히 구분됩니다.

- **확률 (Probability):** **모수(parameter)가 고정**되어 있을 때, 특정 데이터가 관찰될 가능성.
  - `P(data | θ)`
  - 예: 공정한 동전(`θ=p=0.5` 고정)을 던졌을 때, 앞면(`data`)이 나올 확률은 0.5이다.

- **가능도 (Likelihood):** **데이터(data)가 고정(관찰)**되어 있을 때, 이 데이터가 어떤 모수로부터 나왔을지에 대한 그럴듯함의 정도.
  - `L(θ | data)`
  - 예: 동전을 던져 앞면(`data` 관찰)이 나왔을 때, 이 동전이 공정할(`θ=p=0.5`) 가능도는 얼마인가? 또는 앞면이 나올 확률이 `p=0.8`일 가능도는 얼마인가?

수식 `P(data | θ)` 자체는 동일하지만, 무엇을 변수로 보느냐에 따라 확률 함수가 되기도 하고 가능도 함수가 되기도 합니다.

## 2. 가능도 함수 (Likelihood Function)

각 데이터 포인트가 독립적이고 동일한 분포(i.i.d., independent and identically distributed)를 따른다고 가정할 때, 전체 데이터셋에 대한 가능도 함수는 각 데이터 포인트의 확률(또는 확률밀도)의 곱으로 표현됩니다.

`L(θ | x₁, x₂, ..., xₙ) = P(x₁|θ) * P(x₂|θ) * ... * P(xₙ|θ) = Π P(xᵢ|θ)`

**예시: 동전 던지기**
앞면이 나올 확률이 `p`인 동전을 10번 던져 (앞, 앞, 뒤, 앞, 뒤, 앞, 앞, 앞, 뒤, 앞)의 결과가 나왔다고 합시다 (앞면 7번, 뒷면 3번).
이 데이터가 관찰될 가능도 함수는 다음과 같습니다.
`L(p | data) = p * p * (1-p) * p * (1-p) * p * p * p * (1-p) * p = p⁷ * (1-p)³`

우리의 목표는 이 `L(p)`를 최대로 만드는 `p`를 찾는 것입니다.

## 3. 로그 가능도 (Log-Likelihood)

가능도 함수는 여러 확률의 '곱'으로 이루어져 있습니다. 0과 1 사이의 작은 값들을 계속 곱하면 컴퓨터에서 수치적으로 불안정(Numerical Underflow)해질 수 있고, 미분을 통해 최댓값을 찾기도 매우 복잡합니다.

이 문제를 해결하기 위해 **로그(log)**를 사용합니다.
- 로그는 단조 증가 함수이므로, `L(θ)`를 최대로 만드는 `θ`는 `log(L(θ))`를 최대로 만드는 `θ`와 동일합니다.
- 로그의 성질 `log(a*b) = log(a) + log(b)`에 의해, 복잡한 곱셈 연산이 간단한 덧셈 연산으로 바뀝니다.

**로그 가능도 함수:**
`log L(θ | data) = log( Π P(xᵢ|θ) ) = Σ log(P(xᵢ|θ))`

**예시 (계속):**
위 동전 던지기 예시의 로그 가능도 함수는 다음과 같습니다.
`log L(p | data) = log(p⁷ * (1-p)³) = 7 * log(p) + 3 * log(1-p)`

## 4. MLE를 이용한 모수 추정

로그 가능도 함수를 최대로 만드는 모수 `θ`를 찾기 위해, 일반적으로 미분을 사용합니다.
1. 로그 가능도 함수를 모수 `θ`에 대해 미분합니다.
2. 미분한 결과가 0이 되는 `θ` 값을 찾습니다.

**예시 (계속):**
로그 가능도 함수를 `p`에 대해 미분하여 0으로 놓고 풀어봅시다.
`d/dp (log L(p)) = 7/p - 3/(1-p) = 0`
`7/p = 3/(1-p)`
`7(1-p) = 3p`
`7 - 7p = 3p`
`7 = 10p`
`p = 0.7`

**결론:** MLE를 통해 추정한 결과, 우리가 관찰한 데이터를 만들어냈을 가능성이 가장 높은 동전의 앞면이 나올 확률은 **0.7**입니다. 이는 우리의 직관과도 일치하는 합리적인 결과입니다. 이처럼 MLE는 데이터로부터 모델의 최적 파라미터를 학습하는 강력하고 일반적인 방법을 제공합니다.
