# 변이형 오토인코더 (Variational Autoencoders, VAE)

## 1. VAE의 개념: 진정한 생성 모델

**변이형 오토인코더(VAE)**는 기본적인 오토인코더(AE)를 **확률적(probabilistic)**으로 변형하여, 단순히 입력을 압축/복원하는 것을 넘어 **새로운 데이터를 생성(generate)**할 수 있도록 만든 생성 모델(Generative Model)입니다.

기본적인 오토인코더의 잠재 공간(Latent Space)은 불연속적이고 불규칙하여, 잠재 공간의 특정 지점에서 디코딩을 하더라도 의미 있는 데이터를 생성하기 어렵습니다. VAE는 잠재 공간에 **확률 분포(예: 정규 분포)**라는 제약을 가하여, 이 공간을 부드럽고 연속적으로 만들어 생성 모델로서 기능할 수 있게 합니다.

## 2. VAE의 구조와 동작 원리

VAE도 인코더와 디코더 구조를 가지지만, 핵심적인 차이는 인코더의 출력에 있습니다.

1.  **인코더 (Encoder):**
    - VAE의 인코더는 입력($X$)을 받아 잠재 벡터($z$)를 직접 출력하는 대신, 잠재 공간에 존재할 것으로 추정되는 **확률 분포의 파라미터**를 출력합니다.
    - 일반적으로 이 확률 분포는 **정규 분포(Normal Distribution)**로 가정하며, 따라서 인코더는 분포의 **평균($\mu$)**과 **표준편차($\sigma$)** 두 개의 벡터를 출력합니다.

2.  **샘플링 (Sampling):**
    - 인코더가 출력한 평균과 표준편차를 따르는 정규 분포에서 **무작위로 잠재 벡터 $z$를 샘플링**합니다.
    - (기술적으로, 역전파를 가능하게 하기 위해 '재매개변수화 트릭(Reparameterization Trick)'을 사용합니다: $z = \mu + \sigma \odot \epsilon$, 여기서 $\epsilon$은 표준 정규 분포에서 샘플링한 노이즈입니다.)

3.  **디코더 (Decoder):**
    - 샘플링된 잠재 벡터 $z$를 입력으로 받아, 원본 데이터와 유사한 새로운 데이터 $X'$를 생성합니다.

**시각적 구조:**
```
      [입력 데이터 X]
           |
           v
      +-----------+
      |  인코더   |
      +-----------+
           |
           v
  [평균(μ)], [표준편차(σ)]
           |
           v (샘플링)
      [잠재 벡터 z]
           |
           v
      +-----------+
      |  디코더   |
      +-----------+
           |
           v
    [생성된 데이터 X']
```

## 3. VAE의 손실 함수

VAE는 두 가지 손실을 동시에 최소화하는 방향으로 학습됩니다.

### 3.1. 복원 손실 (Reconstruction Loss)
- 입력 데이터($X$)와 디코더가 최종적으로 생성한 데이터($X'$)가 얼마나 유사한지를 측정합니다.
- 이는 기본적인 오토인코더의 손실 함수와 동일하며, 보통 MSE(Mean Squared Error)나 BCE(Binary Cross-Entropy)가 사용됩니다.
- 이 손실은 모델이 데이터를 잘 **복원**하도록 만듭니다.

### 3.2. 정규화 손실 (Regularization Loss): 쿨백-라이블러 발산 (KL-Divergence)
- VAE의 핵심으로, 인코더가 출력한 확률 분포($\mu, \sigma$)가 우리가 가정한 **표준 정규 분포(평균 0, 분산 1)**와 얼마나 다른지를 측정합니다.
- **쿨백-라이블러 발산(KL-Divergence)**이라는 척도를 사용하여 두 확률 분포 간의 차이를 계산합니다.
- 이 손실은 잠재 공간을 **구조화하고(structured) 연속적으로(continuous)** 만들어, 데이터가 없는 빈 공간이 없도록 강제합니다.

**최종 손실:**
$$ \text{Total Loss} = \text{Reconstruction Loss} + \text{KL-Divergence} $$

## 4. 데이터 생성 과정

학습이 완료된 VAE를 사용하여 새로운 데이터를 생성하는 과정은 간단합니다.

1.  표준 정규 분포(평균 0, 분산 1)에서 무작위로 잠재 벡터 $z$를 샘플링합니다.
2.  이 샘플링된 $z$를 **디코더**에 입력합니다.
3.  디코더는 이 잠재 벡터를 해석하여, 학습 데이터와 유사하지만 완전히 새로운 데이터를 생성해냅니다.

## 5. VAE의 특징

- **장점:**
  - 안정적으로 학습이 가능합니다.
  - 잠재 공간이 연속적이고 잘 구조화되어 있어, 잠재 변수를 조작하여 생성되는 데이터의 특성을 제어하기 용이합니다 (예: 웃는 얼굴과 안 웃는 얼굴 사이를 서서히 변화시키는 이미지 생성).
- **단점:**
  - 복원 손실과 KL-Divergence 손실 간의 트레이드오프 관계로 인해, 생성된 이미지가 다소 흐릿하게(blurry) 보이는 경향이 있습니다. 이는 GAN과 비교되는 주요 단점입니다.
