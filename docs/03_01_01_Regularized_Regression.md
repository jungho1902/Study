# 3.1.1. 규제가 있는 회귀 (Regularized Regression)

**규제(Regularization)**는 머신러닝 모델이 훈련 데이터에 너무 과도하게 최적화되는 **과대적합(Overfitting)**을 방지하기 위한 기법입니다. 회귀 모델에서는 모델의 복잡도에 패널티를 부과하여, 특정 가중치(W)의 값이 너무 커지는 것을 막는 방식으로 동작합니다.

모델이 복잡해진다는 것은 가중치(W) 값들이 커진다는 의미이기도 합니다. 가중치가 크면 입력 데이터의 작은 변화에도 예측값이 크게 흔들리게 되어, 모델이 훈련 데이터의 노이즈까지 학습하게 됩니다. 규제는 이러한 가중치의 크기를 제한하여 모델을 더 단순하고 일반화 성능이 좋게 만듭니다.

규제가 있는 회귀 모델은 기존의 비용 함수(Cost Function)에 **규제 항(Regularization Term)**을 더하는 방식으로 구현됩니다.

> **New Cost = Original Cost + Regularization Term**

대표적인 규제 기법으로는 L1 규제와 L2 규제가 있으며, 이를 사용하는 회귀 모델이 각각 라쏘(Lasso)와 릿지(Ridge) 회귀입니다.

---

## 1. 릿지 회귀 (Ridge Regression) - L2 규제

**릿지 회귀(Ridge Regression)**는 **L2 규제**를 사용하는 회귀 모델입니다. L2 규제는 모든 가중치(W)의 **제곱**을 비용 함수에 더하는 방식입니다.

> **L2 Regularization Term = α * Σ W²**

- **Cost(W, b) = MSE + α * Σ W²**
- **α (alpha)**: 규제의 강도를 조절하는 하이퍼파라미터입니다.
  - `α = 0`이면 일반적인 선형 회귀와 동일해집니다.
  - `α`가 커질수록 규제 강도가 강해져 가중치(W)들이 0에 가까워집니다.
  - `α`가 너무 크면 모든 가중치가 0에 가까워져 모델이 과소적합될 수 있습니다.

**특징:**
- L2 규제는 가중치의 크기를 전반적으로 작게 만드는 효과가 있습니다.
- 가중치를 0에 가깝게 만들 수는 있지만, 완전히 0으로 만들지는 않습니다. 따라서 모든 특성(feature)을 모델에 유지합니다.
- 다중공선성(multicollinearity, 특성들 간의 강한 상관관계) 문제가 있을 때 안정적인 성능을 보입니다.

---

## 2. 라쏘 회귀 (Lasso Regression) - L1 규제

**라쏘 회귀(Lasso Regression)**는 **L1 규제**를 사용하는 회귀 모델입니다. L1 규제는 모든 가중치(W)의 **절댓값**을 비용 함수에 더하는 방식입니다.

> **L1 Regularization Term = α * Σ |W|**

- **Cost(W, b) = MSE + α * Σ |W|**

**특징:**
- L1 규제는 중요하지 않은 특성의 가중치를 **완전히 0으로** 만들어 버리는 경향이 있습니다.
- 가중치가 0이 된다는 것은 해당 특성이 모델에서 제외된다는 의미이므로, **특성 선택(Feature Selection)** 효과를 가집니다.
- 모델에 사용하는 특성의 수를 줄여 해석하기 쉽고 가벼운 모델을 만들 수 있습니다.
- 릿지에 비해 계산적으로는 더 복잡할 수 있습니다.

---

## 3. 엘라스틱넷 (ElasticNet)

**엘라스틱넷(ElasticNet)**은 **L1 규제와 L2 규제를 모두 사용**하는 모델입니다. L1 규제(라쏘)와 L2 규제(릿지)의 장점을 결합한 형태라고 할 수 있습니다.

> **ElasticNet Cost = MSE + α * [ (1-r)/2 * Σ W² + r * Σ |W| ]**

- **α (alpha)**: 전체 규제의 강도를 조절합니다.
- **r (l1_ratio)**: L1 규제와 L2 규제의 비율을 조절합니다.
  - `r = 0`이면 L2 규제(릿지)와 동일합니다.
  - `r = 1`이면 L1 규제(라쏘)와 동일합니다.
  - `0 < r < 1`이면 두 규제를 혼합하여 사용합니다.

**특징:**
- 라쏘처럼 특성 선택이 가능하면서도, 릿지처럼 다중공선성 문제에 대해 안정적인 성능을 제공합니다.
- 특성 간 상관관계가 높은 데이터셋에서 라쏘는 일부 특성만 선택하는 경향이 있는 반면, 엘라스틱넷은 상관관계가 있는 특성 그룹을 함께 선택하거나 제외하는 경향이 있습니다.
- 두 개의 하이퍼파라미터(alpha, l1_ratio)를 모두 튜닝해야 하는 단점이 있습니다.

## 4. 정리: Ridge vs Lasso vs ElasticNet

| 구분 | **릿지 (Ridge)** | **라쏘 (Lasso)** | **엘라스틱넷 (ElasticNet)** |
| --- | --- | --- | --- |
| **규제 항** | L2 Norm (가중치 제곱의 합) | L1 Norm (가중치 절댓값의 합) | L1과 L2의 결합 |
| **가중치 처리** | 가중치를 0에 가깝게 줄임 | 중요하지 않은 가중치를 0으로 만듦 | 두 방식의 절충 |
| **특성 선택** | 불가능 | 가능 | 가능 |
| **주요 장점**| 다중공선성에 강함 | 모델 해석 용이, 자동 특성 선택 | 두 모델의 장점을 결합 |
| **하이퍼파라미터** | `alpha` | `alpha` | `alpha`, `l1_ratio` |
