# 3D 비전 (3D Vision)

**3D 비전**은 2D 이미지나 3D 센서 데이터(예: LiDAR, Depth Camera)로부터 3차원 공간과 그 안에 있는 객체들의 구조, 형태, 위치 등을 이해하고 복원하는 컴퓨터 비전의 한 분야입니다. 2D 비전이 이미지 평면에서의 분석에 초점을 맞춘다면, 3D 비전은 실제 세계의 3차원 정보를 다룬다는 점에서 차이가 있습니다.

로보틱스, 자율주행, 증강/가상현실(AR/VR), 의료 영상 등 다양한 분야에서 핵심적인 역할을 합니다.

## 1. 3D 데이터 표현 방식 (3D Data Representations)

3D 객체나 장면을 표현하는 방식은 여러 가지가 있으며, 각각의 장단점이 있습니다.

- **포인트 클라우드 (Point Cloud):**
  - 3D 공간상의 점(point)들의 집합으로, 각 점은 (X, Y, Z) 좌표와 선택적으로 색상(R, G, B), 법선 벡터(normal) 등의 정보를 가집니다.
  - LiDAR 센서나 깊이 카메라에서 직접 얻을 수 있는 원시(raw) 데이터 형태입니다.
  - 구조가 없고 순서가 없어 다루기 까다롭지만, 정밀한 기하학적 정보를 그대로 보존하는 장점이 있습니다.
  - **주요 딥러닝 모델:** PointNet, PointNet++

- **메쉬 (Mesh):**
  - 3D 객체의 표면을 정점(Vertices), 간선(Edges), 면(Faces)의 집합으로 표현합니다. 삼각형 메쉬(triangular mesh)가 가장 일반적입니다.
  - 렌더링에 효율적이며, 표면의 위상(topology) 정보를 명시적으로 표현할 수 있습니다.
  - 게임, 그래픽스, CAD 등에서 널리 사용됩니다.
  - **주요 딥러닝 모델:** MeshCNN, GNN(Graph Neural Networks) 기반 모델

- **복셀 (Voxel):**
  - 3D 공간을 작은 정육면체 격자(grid)로 나눈 것으로, 'Volume + Pixel'의 합성어입니다. 2D 이미지의 픽셀을 3D로 확장한 개념입니다.
  - 3D CNN과 같은 딥러닝 모델을 적용하기 용이하지만, 해상도가 높아지면 메모리 사용량과 계산량이 기하급수적으로 증가하는 단점이 있습니다.

- **암시적 표현 (Implicit Representation):**
  - 3D 형태를 연속적인 함수로 표현합니다. 예를 들어, 특정 좌표 (x, y, z)가 객체의 내부에 있는지 외부에 있는지를 나타내는 함수 `f(x, y, z) = s`를 학습합니다.
  - **NeRF (Neural Radiance Fields)**가 대표적인 예로, 특정 시점(viewpoint)에서 나오는 빛의 색상과 밀도를 예측하는 신경망을 학습하여 매우 사실적인 3D 장면을 복원합니다.
  - 복잡한 형태도 적은 메모리로 표현할 수 있고, 해상도에 제약이 없는 장점이 있습니다.

## 2. 주요 3D 비전 과제

### 2.1. 3D 객체 분류 및 분할 (3D Object Classification & Segmentation)

- 포인트 클라우드나 메쉬 데이터를 입력으로 받아, 해당 객체가 어떤 클래스에 속하는지 분류하거나(Classification), 각 점이나 면이 어떤 부분에 속하는지 분할(Part Segmentation)하는 과제입니다.

### 2.2. 3D 객체 탐지 (3D Object Detection)

- 3D 공간에서 객체의 위치, 크기, 방향을 나타내는 3D 경계 상자(3D Bounding Box)를 찾는 과제입니다.
- 자율주행 자동차가 주변의 다른 차량, 보행자, 장애물 등을 3D로 인식하는 데 핵심적인 기술입니다. LiDAR 데이터나 여러 대의 카메라 이미지를 함께 사용하는 경우가 많습니다.

### 2.3. 3D 재구성 (3D Reconstruction)

- 한 장 또는 여러 장의 2D 이미지로부터 객체나 장면의 3D 모델을 복원하는 기술입니다.
- **Stereo Vision:** 두 대의 카메라(사람의 두 눈과 유사)에서 촬영한 이미지의 시차(disparity)를 이용하여 깊이(depth)를 추정합니다.
- **Structure from Motion (SfM):** 움직이는 카메라로 여러 각도에서 촬영한 이미지들을 이용하여 카메라의 궤적과 3D 포인트 클라우드를 동시에 복원합니다.
- **Photometric Stereo:** 동일한 시점에서 조명의 방향만 바꿔가며 촬영한 이미지들을 이용하여 객체의 표면 법선 벡터를 추정하고 3D 형태를 복원합니다.

### 2.4. SLAM (Simultaneous Localization and Mapping)

- 로봇이나 카메라가 미지의 환경을 움직이면서, 자신의 현재 위치를 추정하는 동시에 주변 환경의 지도를 작성하는 기술입니다.
- **Visual SLAM:** 카메라 이미지만을 사용하여 SLAM을 수행합니다. ORB-SLAM이 대표적입니다.
- **LiDAR SLAM:** LiDAR 센서를 사용하여 더 정밀한 지도를 작성합니다.

3D 비전 기술은 2D 이미지에서는 얻기 힘든 깊이와 공간 정보를 제공함으로써, 기계가 실제 세계와 더 정교하게 상호작용할 수 있도록 만드는 데 필수적입니다.
