# 과대적합 (Overfitting) 과 과소적합 (Underfitting)

머신러닝 모델을 훈련시킬 때의 궁극적인 목표는 훈련 데이터의 패턴을 학습하여, 이전에 본 적 없는 새로운 데이터에 대해서도 정확한 예측을 하는 **일반화(Generalization)** 성능을 높이는 것입니다. 과대적합과 과소적합은 이러한 일반화 성능을 저해하는 대표적인 문제입니다.

---

### 1. 과소적합 (Underfitting)

- **정의:** 모델이 너무 단순하여 훈련 데이터의 기본적인 패턴조차 제대로 학습하지 못하는 상태를 의미합니다.
- **원인:**
  - 모델의 복잡도가 너무 낮을 때 (예: 비선형 데이터에 선형 모델을 사용)
  - 훈련 데이터의 양이 너무 적을 때
  - 특성(feature)이 충분하지 않을 때
- **특징:**
  - 훈련 데이터에 대한 성능(정확도)과 테스트 데이터에 대한 성능이 모두 낮게 나타납니다.
  - 훈련 손실(Training Loss)과 검증 손실(Validation Loss)이 모두 높은 수준에서 더 이상 감소하지 않습니다.
- **해결 방안:**
  - 더 복잡한 모델을 사용합니다 (예: 더 깊은 신경망, 더 높은 차수의 다항 회귀).
  - 더 많은, 또는 더 좋은 특성을 추가합니다.
  - 모델의 규제를 줄입니다.

---

### 2. 과대적합 (Overfitting)

- **정의:** 모델이 훈련 데이터에 너무 과도하게 맞춰져, 데이터의 패턴뿐만 아니라 노이즈(noise)와 세부적인 특성까지 모두 암기해버린 상태를 의미합니다.
- **원인:**
  - 모델의 복잡도가 데이터에 비해 너무 높을 때
  - 훈련 데이터의 양이 부족할 때
  - 훈련을 너무 오래 진행했을 때
- **특징:**
  - **훈련 데이터에 대한 성능은 매우 높지만, 새로운 테스트 데이터에 대한 성능은 현저히 낮게 나타납니다.**
  - 훈련 손실은 계속해서 감소하지만, 검증 손실은 어느 시점부터 다시 증가하는 양상을 보입니다.
- **해결 방안:**
  - **더 많은 훈련 데이터를 수집합니다.** (가장 근본적인 해결책)
  - **규제(Regularization)**를 사용하여 모델의 복잡도에 패널티를 부여합니다 (예: L1/L2 규제).
  - **드롭아웃(Dropout)**을 사용하여 훈련 시 신경망의 일부 뉴런을 무작위로 비활성화합니다 (딥러닝).
  - **가지치기(Pruning)**를 통해 결정 트리의 복잡도를 낮춥니다.
  - **교차 검증(Cross-Validation)**을 사용하여 모델의 일반화 성능을 더 정확하게 평가합니다.

---

### 3. 좋은 적합 (Good Fit)

- **정의:** 과소적합과 과대적합 사이의 균형을 이룬 이상적인 상태입니다. 모델이 데이터의 기본 패턴을 잘 학습하여, 훈련 데이터와 테스트 데이터 모두에서 좋은 성능을 보입니다.
- **특징:** 훈련 손실과 검증 손실이 모두 낮은 수준에서 안정적으로 수렴합니다.

![Fitting Graph](https://miro.medium.com/max/1400/1*sB-yV_5_5-if_aYm2L-i-A.png)
*(이미지 출처: Miro)*

위 그림에서,
- **Underfitting:** 모델(직선)이 데이터의 곡선 패턴을 전혀 따라가지 못합니다.
- **Good Fit / Just Right:** 모델(적절한 곡선)이 데이터의 전반적인 추세를 잘 따릅니다.
- **Overfitting:** 모델(매우 구불구불한 곡선)이 모든 데이터 포인트를 통과하기 위해 비정상적으로 복잡한 형태를 띱니다.
