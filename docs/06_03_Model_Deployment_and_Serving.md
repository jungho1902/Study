# 6.3. 모델 배포 및 서빙 (Model Deployment & Serving)

모델 훈련과 검증이 완료되면, 실제 서비스 환경에서 예측을 생성할 수 있도록 모델을 배포(Deploy)하고 서빙(Serve)해야 합니다. 이 단계는 MLOps 파이프라인에서 가장 중요한 부분 중 하나로, 안정성과 확장성을 보장해야 합니다.

---

### 1. 배포 전략 (Deployment Strategies)

새로운 버전의 모델을 배포할 때는 위험을 최소화하고 서비스 중단을 방지하기 위해 신중한 전략이 필요합니다.

#### 1.1. Shadow Deployment (섀도우 배포)
-   **개념:** 기존 모델(프로덕션 모델)이 실제 트래픽을 처리하는 동안, 새로운 모델(섀도우 모델)을 병렬로 배포합니다. 실제 사용자 요청이 두 모델 모두에 전달되지만, 사용자는 기존 모델의 예측 결과만 받습니다.
-   **장점:**
    -   실제 운영 환경의 데이터로 새 모델의 성능(예측 결과, 지연 시간 등)을 안전하게 테스트할 수 있습니다.
    -   새 모델에 문제가 발생해도 실제 서비스에 영향을 주지 않습니다.
-   **단점:** 두 개의 모델을 동시에 운영해야 하므로 인프라 비용이 두 배로 듭니다.

#### 1.2. Canary Deployment (카나리 배포)
-   **개념:** 전체 사용자 중 아주 작은 일부(예: 1~5%)에게만 새로운 모델을 노출하고, 나머지는 기존 모델을 사용하게 합니다. 새 모델이 안정적으로 동작한다고 판단되면 점진적으로 트래픽 비중을 늘려나갑니다.
-   **장점:**
    -   문제가 발생하더라도 영향을 받는 사용자가 소수에 그치므로 위험을 최소화할 수 있습니다.
    -   실제 사용자 피드백을 기반으로 점진적으로 롤아웃(Rollout)할 수 있습니다.
-   **단점:** 트래픽을 정교하게 라우팅하고 관리하기 위한 추가적인 기술이 필요합니다.

#### 1.3. A/B Testing (A/B 테스팅)
-   **개념:** 특정 비즈니스 지표(예: 클릭률, 구매 전환율)를 기준으로 두 개 이상의 모델(예: 기존 모델 A vs. 신규 모델 B)의 성능을 비교 평가하는 방법입니다. 사용자를 여러 그룹으로 나누어 각 그룹에 다른 모델의 예측을 제공하고, 어떤 모델이 더 나은 성과를 내는지 통계적으로 검증합니다.
-   **장점:**
    -   데이터에 기반하여 어떤 모델이 비즈니스 목표에 더 기여하는지 명확하게 판단할 수 있습니다.
-   **단점:**
    -   결과를 신뢰하기 위해 충분한 데이터와 시간이 필요합니다.
    -   실험 설계 및 결과 분석이 복잡할 수 있습니다.

---

### 2. 모델 서빙 (Model Serving)

모델 서빙은 배포된 모델이 예측 요청을 처리하고 응답을 반환하는 방식입니다.

#### 2.1. 온라인 서빙 (Online/Real-time Serving)
-   **개념:** 사용자 요청이 들어올 때마다 즉시 예측을 반환하는 방식입니다.
-   **통신 방식:** 주로 **REST API**나 **gRPC**를 사용합니다.
    -   **REST API:** HTTP/JSON 기반으로 구현이 간단하고 범용성이 높습니다.
    -   **gRPC:** Protocol Buffers를 사용하여 데이터를 직렬화하며, HTTP/2 기반으로 동작하여 REST API보다 성능이 우수하고 지연 시간이 짧습니다.
-   **적용 분야:** 실시간 추천, 사기 탐지, 이미지 인식 등 즉각적인 응답이 필요한 서비스에 사용됩니다.

#### 2.2. 배치 서빙 (Batch Serving)
-   **개념:** 대량의 데이터를 한 번에 모아 주기적으로 예측을 수행하는 방식입니다. 실시간 응답이 필요 없는 경우에 사용됩니다.
-   **작동 방식:** 정해진 스케줄(예: 매일 자정)에 따라 대용량 데이터를 입력으로 모델을 실행하고, 예측 결과를 데이터베이스나 파일 시스템에 저장합니다.
-   **적용 분야:** 사용자 행동 예측, 재고 수요 예측, 대규모 데이터 라벨링 등 대용량 처리가 필요한 작업에 적합합니다.

---

### 3. 컨테이너화 (Containerization)

컨테이너화는 모델과 실행에 필요한 모든 종속성(라이브러리, 환경 변수 등)을 하나의 '컨테이너' 이미지로 패키징하는 기술입니다. 이를 통해 "제 컴퓨터에서는 잘 됐는데..."와 같은 문제를 해결하고, 개발과 운영 환경을 일치시킬 수 있습니다.

#### 3.1. Docker
-   **개념:** 컨테이너 기술의 사실상 표준입니다. `Dockerfile`이라는 설정 파일을 통해 컨테이너 이미지를 손쉽게 만들고, 배포하며, 실행할 수 있습니다.
-   **장점:**
    -   **이식성:** 로컬 머신, 테스트 서버, 프로덕션 클라우드 등 어디서나 동일한 환경으로 실행 가능합니다.
    -   **재현성:** 코드, 라이브러리, 설정이 모두 이미지에 포함되어 있어 예측 결과를 일관되게 재현할 수 있습니다.
    -   **격리:** 컨테이너는 호스트 시스템 및 다른 컨테이너와 격리되어 안정성을 높입니다.

#### 3.2. Kubernetes (K8s)
-   **개념:** Docker와 같은 컨테이너화된 애플리케이션을 대규모로 관리, 배포, 확장하기 위한 컨테이너 오케스트레이션(Container Orchestration) 플랫폼입니다.
-   **주요 기능:**
    -   **자동 확장 (Auto-scaling):** 트래픽 양에 따라 컨테이너 수를 자동으로 늘리거나 줄입니다.
    -   **자가 치유 (Self-healing):** 특정 컨테이너에 문제가 생기면 자동으로 재시작하거나 교체합니다.
    -   **무중단 업데이트 (Rolling Updates):** 서비스 중단 없이 모델을 새로운 버전으로 업데이트합니다.

---

### 4. 서버리스 배포 (Serverless Deployment)

서버리스는 개발자가 서버를 직접 프로비저닝하거나 관리할 필요 없이 코드를 실행할 수 있게 해주는 클라우드 컴퓨팅 모델입니다.

-   **개념:** 클라우드 제공업체가 인프라 관리를 모두 처리하며, 사용자는 코드를 함수(Function) 형태로 업로드하기만 하면 됩니다. 요청이 있을 때만 코드가 실행되고, 실행된 시간만큼만 비용을 지불합니다.
-   **장점:**
    -   **비용 효율성:** 유휴 시간(idle time)에 대한 비용이 없습니다.
    -   **관리 부담 감소:** 서버, OS, 보안 패치 등을 신경 쓸 필요가 없습니다.
    -   **자동 확장:** 트래픽에 따라 클라우드가 자동으로 확장/축소를 처리합니다.
-   **단점:**
    -   **콜드 스타트 (Cold Start):** 오랫동안 호출되지 않은 함수는 처음 실행될 때 지연이 발생할 수 있습니다.
    -   실행 시간이나 메모리 등 리소스에 제약이 있을 수 있습니다.
-   **대표적인 서비스:** **AWS Lambda**, **Google Cloud Functions**, **Azure Functions** 등이 있으며, 간단한 모델이나 트래픽이 불규칙한 서비스 배포에 적합합니다.
