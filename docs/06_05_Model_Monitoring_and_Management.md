# 6.5. 모델 모니터링 및 관리 (Model Monitoring & Management)

모델을 성공적으로 배포했다고 해서 MLOps의 여정이 끝나는 것은 아닙니다. 배포된 모델이 시간이 지나도 안정적으로 좋은 성능을 유지하는지 지속적으로 감시하고 관리하는 것이 중요합니다. 이 단계는 모델의 신뢰성을 보장하고 비즈니스 가치를 유지하는 데 필수적입니다.

---

### 1. 모델 성능 모니터링 (Model Performance Monitoring)

배포된 모델이 실제 운영 환경에서 얼마나 잘 작동하는지 추적하는 과정입니다.

-   **모니터링 대상:**
    -   **소프트웨어 성능:** 모델 서빙 API의 응답 지연 시간(Latency), 초당 처리량(Throughput), 에러율(Error Rate), CPU/메모리 사용량 등 시스템 메트릭을 모니터링합니다.
    -   **모델 예측 성능:** 모델의 예측 결과 품질을 측정합니다.
        -   **정답(Ground Truth)이 바로 확인될 때:** 사용자의 피드백(예: 추천 클릭 여부)을 통해 실시간으로 정확도, 정밀도, 재현율 등을 계산할 수 있습니다.
        -   **정답 확인이 지연될 때:** 정답 데이터가 수집될 때까지 기다렸다가 주기적으로 성능을 평가합니다. 또는, 정답 없이도 예측 결과의 분포 변화나 안정성 등을 통해 간접적으로 성능을 추론합니다.

---

### 2. 데이터 드리프트와 컨셉 드리프트 (Data Drift & Concept Drift)

시간이 지남에 따라 모델의 성능이 저하되는 주요 원인은 '드리프트'입니다. 이를 탐지하고 대응하는 것이 모니터링의 핵심 목표입니다.

#### 2.1. 데이터 드리프트 (Data Drift)
-   **정의:** 입력 데이터의 통계적 분포가 모델 학습 시점의 데이터 분포와 달라지는 현상입니다. 모델은 학습 데이터에서 발견된 패턴을 기반으로 예측하므로, 입력 데이터의 특성이 바뀌면 성능이 저하될 수 있습니다.
-   **예시:**
    -   코로나19 이후 사람들의 온라인 쇼핑 품목 분포가 이전과 크게 달라진 경우
    -   새로운 유형의 사용자가 유입되면서 평균 연령대나 지역 분포가 바뀐 경우
-   **탐지 방법:** 학습 데이터의 통계(평균, 분산, 데이터 분포 등)와 현재 들어오는 데이터의 통계를 비교하여 차이가 유의미하게 벌어지는지 감지합니다. (예: Kolmogorov-Smirnov test, Population Stability Index 등)

#### 2.2. 컨셉 드리프트 (Concept Drift)
-   **정의:** 입력 데이터와 타겟 변수(정답) 사이의 관계 자체가 변하는, 더 근본적인 변화입니다. 데이터 분포는 그대로일 수 있지만, 동일한 입력에 대한 정답이 바뀌는 현상입니다.
-   **예시:**
    -   부동산 시장의 정책 변화로 인해, 이전에는 집값 상승의 주요 요인이었던 '역세권'의 중요도가 감소한 경우
    -   스팸 메일 필터링 모델에서, 스패머들이 기존 패턴을 회피하는 새로운 유형의 스팸 메일을 보내기 시작한 경우
-   **탐지 방법:** 컨셉 드리프트는 데이터만으로는 탐지하기 어렵고, 주로 모델의 예측 성능(정확도, F1-score 등)이 저하되는 것을 통해 간접적으로 감지합니다.

-   **드리프트 대응:** 드리프트가 탐지되면, 이는 모델이 현실 세계의 변화를 따라가지 못하고 있다는 신호입니다. 이때 **지속적 학습(Continuous Training)** 파이프라인을 트리거하여 최신 데이터로 모델을 재학습하고 업데이트해야 합니다.

---

### 3. 모델 레지스트리 (Model Registry)

모델 레지스트리는 훈련된 모든 머신러닝 모델의 버전, 아티팩트, 메타데이터를 중앙에서 체계적으로 관리하는 저장소입니다.

-   **주요 기능:**
    -   **버전 관리:** 어떤 데이터와 코드로 어떤 모델이 만들어졌는지 모든 버전을 추적합니다. (예: `customer-churn-v1.2`)
    -   **아티팩트 저장:** 모델 파일(예: `model.pkl`), 직렬화된 객체, 설정 파일 등 모델과 관련된 모든 파일을 저장합니다.
    -   **메타데이터 관리:** 모델의 성능 지표, 학습 날짜, 담당자, 모델 설명 등 중요한 정보를 함께 기록합니다.
    -   **모델 생명주기 관리:** 모델의 상태(예: `개발중`, `스테이징`, `프로덕션`, `폐기`)를 관리하여, 승인된 모델만 배포되도록 통제합니다.

-   **필요성:**
    -   **재현성 및 투명성:** 언제든지 특정 버전의 모델을 가져와 결과를 재현하고, 모델의 이력을 투명하게 관리할 수 있습니다.
    -   **거버넌스 및 규제 준수:** 모델의 승인 및 배포 과정을 통제하여 안정성을 높이고, 규제 요구사항을 충족하는 데 도움을 줍니다.

---

### 4. 주요 MLOps 플랫폼 (Major MLOps Platforms)

전체 MLOps 파이프라인 구축을 돕는 다양한 오픈소스 및 상용 플랫폼이 있습니다.

-   **MLflow:**
    -   **특징:** 모델의 실험 추적(Tracking), 모델 패키징(Projects), 모델 버전 관리 및 배포(Models) 등 MLOps의 핵심 기능을 모듈식으로 제공하는 경량 오픈소스 플랫폼입니다.
    -   **장점:** 시작하기 쉽고, 기존 워크플로우에 유연하게 통합할 수 있습니다.

-   **Kubeflow:**
    -   **특징:** Kubernetes 위에서 실행되는 MLOps 플랫폼으로, 컨테이너 기반의 확장 가능하고 이식성 높은 ML 워크플로우를 구축하는 데 초점을 맞춥니다.
    -   **장점:** 복잡하고 대규모의 ML 파이프라인을 관리하는 데 강력한 기능을 제공합니다.

-   **TFX (TensorFlow Extended):**
    -   **특징:** Google에서 개발한 TensorFlow 기반의 엔드투엔드 MLOps 플랫폼입니다. 데이터 검증, 피처 엔지니어링, 모델 분석 등 프로덕션 환경에 필요한 다양한 컴포넌트를 제공합니다.
    -   **장점:** 대규모 프로덕션 환경에서 검증된 안정성과 완성도 높은 기능을 자랑합니다.

-   **클라우드 기반 MLOps 플랫폼:**
    -   **Amazon SageMaker:** AWS의 완전 관리형 ML 서비스로, 데이터 준비부터 모델 훈련, 배포, 모니터링까지 전 과정을 통합적으로 지원합니다.
    -   **Google Cloud AI Platform (Vertex AI):** Google Cloud의 통합 AI 개발 플랫폼으로, AutoML, MLOps 파이프라인, 피처 스토어 등 포괄적인 기능을 제공합니다.
    -   **Azure Machine Learning:** Microsoft Azure의 ML 서비스로, 시각적인 디자이너와 코드 기반 개발 환경을 모두 지원하여 다양한 수준의 사용자를 만족시킵니다.
